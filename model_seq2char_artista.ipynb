{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c2d31ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPU:  1\n",
      "GPU Name:  NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "Using device: cuda\n",
      "Tensor on GPU: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"Number of GPU: \", torch.cuda.device_count())\n",
    "print(\"GPU Name: \", torch.cuda.get_device_name())\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Exemplo rápido para confirmar que está usando a GPU\n",
    "x = torch.rand(5, 5).to(device)\n",
    "y = torch.rand(5, 5).to(device)\n",
    "z = x @ y\n",
    "print(\"Tensor on GPU:\", z.is_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac79220",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import spacy\n",
    "import nltk\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124240a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "except LookupError:\n",
    "    print(\"Downloading 'punkt' NLTK package...\")\n",
    "    nltk.download('punkt')\n",
    "try:\n",
    "    nltk.data.find('corpora/wordnet')\n",
    "except LookupError:\n",
    "    print(\"Downloading 'wordnet' NLTK package...\")\n",
    "    nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f920c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando a contagem de músicas em todos os arquivos CSV...\n",
      "Processando arquivo: ArianaGrande.csv\n",
      "Processando arquivo: Beyonce.csv\n",
      "Processando arquivo: BillieEilish.csv\n",
      "Processando arquivo: BTS.csv\n",
      "Processando arquivo: CardiB.csv\n",
      "Processando arquivo: CharliePuth.csv\n",
      "Processando arquivo: ColdPlay.csv\n",
      "Processando arquivo: Drake.csv\n",
      "Processando arquivo: DuaLipa.csv\n",
      "Processando arquivo: EdSheeran.csv\n",
      "Processando arquivo: Eminem.csv\n",
      "Processando arquivo: JustinBieber.csv\n",
      "Processando arquivo: KatyPerry.csv\n",
      "Processando arquivo: Khalid.csv\n",
      "Processando arquivo: LadyGaga.csv\n",
      "Processando arquivo: Maroon5.csv\n",
      "Processando arquivo: NickiMinaj.csv\n",
      "Processando arquivo: PostMalone.csv\n",
      "Processando arquivo: Rihanna.csv\n",
      "Processando arquivo: SelenaGomez.csv\n",
      "Processando arquivo: TaylorSwift.csv\n",
      "\n",
      "--- Resultados ---\n",
      "Número total de músicas (antes da limpeza): 6027\n",
      "Número de letras válidas (após remover placeholder e vazias): 5752\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Conta o número total de músicas a partir de arquivos CSV na pasta 'csv',\n",
    "antes e depois da limpeza, filtrando letras vazias e uma frase de placeholder específica.\n",
    "\"\"\"\n",
    "CSV_FOLDER_PATH = 'csv'\n",
    "PLACEHOLDER_PHRASE = \"lyrics for this song have yet to be released please check back once the song has been released\"\n",
    "\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'[^a-z0-9\\s.,!?;:\\'\\-]', '', text)\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        return text\n",
    "    return \"\"\n",
    "\n",
    "total_songs_raw = 0\n",
    "total_songs_after_cleaning = 0\n",
    "\n",
    "print(\"Iniciando a contagem de músicas em todos os arquivos CSV...\")\n",
    "\n",
    "for filename in os.listdir(CSV_FOLDER_PATH):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        csv_path = os.path.join(CSV_FOLDER_PATH, filename)\n",
    "        print(f\"Processando arquivo: {filename}\")\n",
    "        \n",
    "        try:\n",
    "            df = pd.read_csv(csv_path, usecols=['Lyric'])\n",
    "            \n",
    "            total_songs_raw += len(df)\n",
    "            \n",
    "            df['Cleaned_Lyric'] = df['Lyric'].apply(clean_text)\n",
    "            \n",
    "            df_filtered = df[df['Cleaned_Lyric'] != '']\n",
    "            \n",
    "            df_filtered = df_filtered[~df_filtered['Cleaned_Lyric'].str.contains(PLACEHOLDER_PHRASE, na=False)]\n",
    "            \n",
    "            total_songs_after_cleaning += len(df_filtered)\n",
    "            \n",
    "        except KeyError:\n",
    "            print(f\"Aviso: Coluna 'Lyric' não encontrada em {filename}. Pulando este arquivo.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao processar {filename}: {e}. Pulando este arquivo.\")\n",
    "\n",
    "print(\"\\n--- Resultados ---\")\n",
    "print(f\"Número total de músicas (antes da limpeza): {total_songs_raw}\")\n",
    "print(f\"Número de letras válidas (após remover placeholder e vazias): {total_songs_after_cleaning}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a46cde",
   "metadata": {},
   "source": [
    "## Separação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77933d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passo 1-3: Coletando e limpando as letras para o artista 'ArianaGrande' do arquivo 'csv\\ArianaGrande.csv'...\n",
      "Processando todas as 308 músicas de 'ArianaGrande'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Limpando e filtrando letras de ArianaGrande: 100%|██████████| 308/308 [00:00<00:00, 5225.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de letras iniciais: 308\n",
      "Total de letras coletadas e limpas para 'ArianaGrande': 294\n",
      "\n",
      "Divisão das músicas:\n",
      "Treino: 235 músicas\n",
      "Validação: 29 músicas\n",
      "Teste: 30 músicas\n",
      "\n",
      "Passo 4: Construindo vocabulário de caracteres com as letras de TREINO...\n",
      "Vocabulário de caracteres construído. Tamanho do vocabulário: 36\n",
      "Objeto salvo em: processed_data_by_artist_char_split\\arianagrande\\tokenizers\\char_tokenizer_arianagrande.pkl\n",
      "\n",
      "Conjunto de Treino: Criando sequências e tokenizando...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Conjunto de Treino músicas: 100%|██████████| 235/235 [00:01<00:00, 148.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de caracteres processados no Conjunto de Treino: 383150\n",
      "Total de sequências criadas para Conjunto de Treino: 360363\n",
      "\n",
      "Conjunto de Validação: Criando sequências e tokenizando...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Conjunto de Validação músicas: 100%|██████████| 29/29 [00:00<00:00, 72.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de caracteres processados no Conjunto de Validação: 42771\n",
      "Total de sequências criadas para Conjunto de Validação: 39968\n",
      "\n",
      "Conjunto de Teste: Criando sequências e tokenizando...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Conjunto de Teste músicas: 100%|██████████| 30/30 [00:00<00:00, 281.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de caracteres processados no Conjunto de Teste: 53235\n",
      "Total de sequências criadas para Conjunto de Teste: 50300\n",
      "\n",
      "Shapes finais dos dados tokenizados:\n",
      "X_train shape: (360363, 100), y_train shape: (360363,)\n",
      "X_val shape: (39968, 100), y_val shape: (39968,)\n",
      "X_test shape: (50300, 100), y_test shape: (50300,)\n",
      "Dados de TREINO salvos em processed_data_by_artist_char_split\\arianagrande\\data\\X_train_arianagrande_char.npy e processed_data_by_artist_char_split\\arianagrande\\data\\y_train_arianagrande_char.npy\n",
      "Dados de VALIDAÇÃO salvos em processed_data_by_artist_char_split\\arianagrande\\data\\X_val_arianagrande_char.npy e processed_data_by_artist_char_split\\arianagrande\\data\\y_val_arianagrande_char.npy\n",
      "Dados de TESTE salvos em processed_data_by_artist_char_split\\arianagrande\\data\\X_test_arianagrande_char.npy e processed_data_by_artist_char_split\\arianagrande\\data\\y_test_arianagrande_char.npy\n",
      "Objeto salvo em: processed_data_by_artist_char_split\\arianagrande\\tokenizers\\vocab_size_arianagrande_char.pkl\n",
      "Tamanho do vocabulário salvo em processed_data_by_artist_char_split\\arianagrande\\tokenizers\\vocab_size_arianagrande_char.pkl\n",
      "\n",
      "Pré-processamento para o artista 'ArianaGrande' (caractere a caractere) concluído.\n",
      "Dados tokenizados salvos no diretório: processed_data_by_artist_char_split\\arianagrande\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Configura os parâmetros para o pré-processamento de um artista específico,\n",
    "define as funções e a classe de tokenização necessárias, processa as letras\n",
    "do artista em sequências de caracteres e salva os conjuntos de dados de treino,\n",
    "validação e teste, bem como o tokenizador.\n",
    "\"\"\"\n",
    "# --- Configurações Específicas desta Célula ---\n",
    "SEQUENCE_LENGTH = 100\n",
    "BASE_OUTPUT_DIR = 'processed_data_by_artist_char_split'\n",
    "TOKENIZER_SUBDIR = 'tokenizers'\n",
    "DATA_SUBDIR = 'data'\n",
    "TARGET_ARTIST = 'ArianaGrande'\n",
    "NUM_SONGS_TO_PROCESS = -1\n",
    "TRAIN_SPLIT = 0.8\n",
    "VAL_SPLIT = 0.1\n",
    "TEST_SPLIT = 0.1\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# --- Geração de Nomes e Estrutura de Pastas ---\n",
    "CLEAN_TARGET_ARTIST_NAME = TARGET_ARTIST.replace(\" \", \"_\").replace(\".\", \"\").lower()\n",
    "CSV_FILE_PATH = os.path.join(CSV_FOLDER_PATH, f'{TARGET_ARTIST}.csv')\n",
    "OUTPUT_DIR_ARTIST = os.path.join(BASE_OUTPUT_DIR, CLEAN_TARGET_ARTIST_NAME)\n",
    "os.makedirs(os.path.join(OUTPUT_DIR_ARTIST, TOKENIZER_SUBDIR), exist_ok=True)\n",
    "os.makedirs(os.path.join(OUTPUT_DIR_ARTIST, DATA_SUBDIR), exist_ok=True)\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "# --- Funções e Classes Auxiliares Novas ---\n",
    "def save_object(obj, path):\n",
    "    with open(path, 'wb') as handle:\n",
    "        pickle.dump(obj, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print(f\"Objeto salvo em: {path}\")\n",
    "\n",
    "def load_object(path):\n",
    "    if os.path.exists(path):\n",
    "        with open(path, 'rb') as handle:\n",
    "            obj = pickle.load(handle)\n",
    "        print(f\"Objeto carregado de: {path}\")\n",
    "        return obj\n",
    "    return None\n",
    "\n",
    "class CharacterTokenizer:\n",
    "    def __init__(self):\n",
    "        self.char_to_int = {}\n",
    "        self.int_to_char = {}\n",
    "        self.vocab_size = 0\n",
    "\n",
    "    def fit_on_texts(self, texts):\n",
    "        all_chars = \"\".join(texts) if isinstance(texts, list) else texts\n",
    "        unique_chars = sorted(list(set(all_chars)))\n",
    "        self.char_to_int = {char: i + 1 for i, char in enumerate(unique_chars)}\n",
    "        self.int_to_char = {i + 1: char for i, char in enumerate(unique_chars)}\n",
    "        self.vocab_size = len(self.char_to_int) + 1\n",
    "\n",
    "    def texts_to_sequences(self, texts):\n",
    "        if isinstance(texts, str):\n",
    "            return [self.char_to_int.get(char, 0) for char in texts]\n",
    "        elif isinstance(texts, list):\n",
    "            return [[self.char_to_int.get(char, 0) for char in s] for s in texts]\n",
    "        return []\n",
    "\n",
    "    def sequences_to_texts(self, sequences):\n",
    "        if sequences and isinstance(sequences[0], list):\n",
    "            return [\"\".join([self.int_to_char.get(i, '') for i in seq]) for seq in sequences]\n",
    "        else:\n",
    "            return \"\".join([self.int_to_char.get(i, '') for i in sequences])\n",
    "\n",
    "# --- Lógica Principal de Processamento ---\n",
    "print(f\"Coletando e limpando as letras para o artista '{TARGET_ARTIST}'...\")\n",
    "all_lyrics_for_split = []\n",
    "try:\n",
    "    df_artist = pd.read_csv(CSV_FILE_PATH, usecols=['Lyric'])\n",
    "    \n",
    "    lyrics_to_process_df = df_artist\n",
    "    if NUM_SONGS_TO_PROCESS != -1 and NUM_SONGS_TO_PROCESS < len(df_artist):\n",
    "        lyrics_to_process_df = df_artist.sample(n=NUM_SONGS_TO_PROCESS, random_state=RANDOM_SEED)\n",
    "        print(f\"Selecionando aleatoriamente {NUM_SONGS_TO_PROCESS} músicas de '{TARGET_ARTIST}'.\")\n",
    "    else:\n",
    "        print(f\"Processando todas as {len(df_artist)} músicas de '{TARGET_ARTIST}'.\")\n",
    "\n",
    "    for lyric_val in tqdm(lyrics_to_process_df['Lyric'], desc=f\"Limpando letras de {TARGET_ARTIST}\"):\n",
    "        cleaned_lyric = clean_text(lyric_val)\n",
    "        if cleaned_lyric and PLACEHOLDER_PHRASE not in cleaned_lyric:\n",
    "            all_lyrics_for_split.append(cleaned_lyric)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Erro: Arquivo CSV não encontrado em '{CSV_FILE_PATH}'. Verifique o caminho e nome do arquivo.\")\n",
    "except KeyError:\n",
    "    print(\"Erro: Coluna 'Lyric' não encontrada no CSV. Verifique o nome da coluna (case-sensitive).\")\n",
    "\n",
    "print(f\"Total de letras válidas coletadas: {len(all_lyrics_for_split)}\")\n",
    "\n",
    "random.shuffle(all_lyrics_for_split)\n",
    "num_train = int(len(all_lyrics_for_split) * TRAIN_SPLIT)\n",
    "num_val = int(len(all_lyrics_for_split) * VAL_SPLIT)\n",
    "train_lyrics = all_lyrics_for_split[:num_train]\n",
    "val_lyrics = all_lyrics_for_split[num_train : num_train + num_val]\n",
    "test_lyrics = all_lyrics_for_split[num_train + num_val :]\n",
    "\n",
    "print(f\"\\nDivisão das músicas: Treino={len(train_lyrics)}, Validação={len(val_lyrics)}, Teste={len(test_lyrics)}\")\n",
    "\n",
    "print(\"\\nConstruindo vocabulário de caracteres com as letras de TREINO...\")\n",
    "tokenizer = CharacterTokenizer()\n",
    "tokenizer.fit_on_texts(\" \".join(train_lyrics))\n",
    "total_chars = tokenizer.vocab_size\n",
    "print(f\"Vocabulário construído. Tamanho do vocabulário: {total_chars}\")\n",
    "\n",
    "def create_sequences_from_lyrics_list(lyrics_list, tokenizer, sequence_length, description):\n",
    "    all_sequences, all_next_chars = [], []\n",
    "    print(f\"\\nCriando sequências para o {description}...\")\n",
    "    for lyric in tqdm(lyrics_list, desc=f\"Processando músicas do {description}\"):\n",
    "        tokenized_lyric = tokenizer.texts_to_sequences(lyric)\n",
    "        if len(tokenized_lyric) < sequence_length + 1:\n",
    "            continue\n",
    "        for i in range(len(tokenized_lyric) - sequence_length):\n",
    "            seq = tokenized_lyric[i : i + sequence_length]\n",
    "            next_c = tokenized_lyric[i + sequence_length]\n",
    "            all_sequences.append(seq)\n",
    "            all_next_chars.append(next_c)\n",
    "    print(f\"Total de sequências criadas para {description}: {len(all_sequences)}\")\n",
    "    if not all_sequences:\n",
    "        return np.array([]), np.array([])\n",
    "    return np.array(all_sequences, dtype=np.int32), np.array(all_next_chars, dtype=np.int32)\n",
    "\n",
    "X_train, y_train = create_sequences_from_lyrics_list(train_lyrics, tokenizer, SEQUENCE_LENGTH, \"Conjunto de Treino\")\n",
    "X_val, y_val = create_sequences_from_lyrics_list(val_lyrics, tokenizer, SEQUENCE_LENGTH, \"Conjunto de Validação\")\n",
    "X_test, y_test = create_sequences_from_lyrics_list(test_lyrics, tokenizer, SEQUENCE_LENGTH, \"Conjunto de Teste\")\n",
    "\n",
    "print(f\"\\nShapes finais dos dados tokenizados:\")\n",
    "print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
    "\n",
    "print(\"\\nSalvando dados processados e tokenizador...\")\n",
    "TOKENIZER_SAVE_PATH = os.path.join(OUTPUT_DIR_ARTIST, TOKENIZER_SUBDIR, f'char_tokenizer_{CLEAN_TARGET_ARTIST_NAME}.pkl')\n",
    "save_object(tokenizer, TOKENIZER_SAVE_PATH)\n",
    "\n",
    "output_file_x_train = os.path.join(OUTPUT_DIR_ARTIST, DATA_SUBDIR, f'X_train_{CLEAN_TARGET_ARTIST_NAME}_char.npy')\n",
    "output_file_y_train = os.path.join(OUTPUT_DIR_ARTIST, DATA_SUBDIR, f'y_train_{CLEAN_TARGET_ARTIST_NAME}_char.npy')\n",
    "np.save(output_file_x_train, X_train)\n",
    "np.save(output_file_y_train, y_train)\n",
    "print(f\"Dados de TREINO salvos.\")\n",
    "\n",
    "output_file_x_val = os.path.join(OUTPUT_DIR_ARTIST, DATA_SUBDIR, f'X_val_{CLEAN_TARGET_ARTIST_NAME}_char.npy')\n",
    "output_file_y_val = os.path.join(OUTPUT_DIR_ARTIST, DATA_SUBDIR, f'y_val_{CLEAN_TARGET_ARTIST_NAME}_char.npy')\n",
    "np.save(output_file_x_val, X_val)\n",
    "np.save(output_file_y_val, y_val)\n",
    "print(f\"Dados de VALIDAÇÃO salvos.\")\n",
    "\n",
    "output_file_x_test = os.path.join(OUTPUT_DIR_ARTIST, DATA_SUBDIR, f'X_test_{CLEAN_TARGET_ARTIST_NAME}_char.npy')\n",
    "output_file_y_test = os.path.join(OUTPUT_DIR_ARTIST, DATA_SUBDIR, f'y_test_{CLEAN_TARGET_ARTIST_NAME}_char.npy')\n",
    "np.save(output_file_x_test, X_test)\n",
    "np.save(output_file_y_test, y_test)\n",
    "print(f\"Dados de TESTE salvos.\")\n",
    "\n",
    "output_file_vocab_size = os.path.join(OUTPUT_DIR_ARTIST, TOKENIZER_SUBDIR, f'vocab_size_{CLEAN_TARGET_ARTIST_NAME}_char.pkl')\n",
    "save_object(total_chars, output_file_vocab_size)\n",
    "\n",
    "print(f\"\\nPré-processamento para o artista '{TARGET_ARTIST}' concluído.\")\n",
    "print(f\"Dados tokenizados salvos no diretório: {OUTPUT_DIR_ARTIST}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1592e572",
   "metadata": {},
   "source": [
    "## Treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e3014c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cuda\n",
      "\n",
      "Iniciando treinamento de nível de caractere para o artista: 'ArianaGrande'...\n",
      "Objeto carregado de: processed_data_by_artist_char_split\\arianagrande\\tokenizers\\char_tokenizer_arianagrande.pkl\n",
      "Objeto carregado de: processed_data_by_artist_char_split\\arianagrande\\tokenizers\\vocab_size_arianagrande_char.pkl\n",
      "Vocabulário de caracteres carregado. Tamanho do vocabulário: 36\n",
      "Dataset de treino com 360678 amostras, 2818 batches.\n",
      "Dataset de validação com 44889 amostras, 351 batches.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Configura os parâmetros de treinamento, define as classes de Dataset e do\n",
    "modelo LSTM, carrega os dados pré-processados e inicializa os componentes\n",
    "para o treinamento do modelo de geração de texto para o artista alvo.\n",
    "\"\"\"\n",
    "# --- Configurações do Treinamento ---\n",
    "MODEL_DIR_BASE = 'models_by_artist_char_split'\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando dispositivo: {device}\")\n",
    "\n",
    "# --- Caminhos Específicos do Modelo ---\n",
    "MODEL_DIR_ARTIST = os.path.join(MODEL_DIR_BASE, CLEAN_TARGET_ARTIST_NAME)\n",
    "os.makedirs(MODEL_DIR_ARTIST, exist_ok=True)\n",
    "\n",
    "# --- Definição do Dataset e Modelo PyTorch ---\n",
    "class LyricsDataset(Dataset):\n",
    "    def __init__(self, x_tokens_path, y_tokens_path):\n",
    "        self.x_data = np.load(x_tokens_path, mmap_mode='r')\n",
    "        self.y_data = np.load(y_tokens_path, mmap_mode='r')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x_sample = torch.tensor(self.x_data[idx], dtype=torch.long)\n",
    "        y_sample = torch.tensor(self.y_data[idx], dtype=torch.long)\n",
    "        return x_sample, y_sample\n",
    "\n",
    "class CharLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, n_layers, dropout_rate, dropout_strategy=\"none\"):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_strategy = dropout_strategy\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        lstm_dropout_param = dropout_rate if dropout_strategy == \"between_lstm\" and n_layers > 1 else 0.0\n",
    "        self.lstm = nn.LSTM(embedding_dim,\n",
    "                              hidden_dim,\n",
    "                              n_layers,\n",
    "                              dropout=lstm_dropout_param,\n",
    "                              batch_first=True,\n",
    "                              bidirectional=True)\n",
    "        \n",
    "        self.dropout_layer = nn.Dropout(dropout_rate)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, vocab_size)\n",
    "\n",
    "    def forward(self, text):\n",
    "        embedded = self.embedding(text)\n",
    "        output, (hidden, cell) = self.lstm(embedded)\n",
    "        final_lstm_output = output[:, -1, :]\n",
    "\n",
    "        if self.dropout_strategy == \"before_fc\":\n",
    "            final_lstm_output = self.dropout_layer(final_lstm_output)\n",
    "        \n",
    "        prediction = self.fc(final_lstm_output)\n",
    "        return prediction\n",
    "\n",
    "# --- Preparação para o Treinamento do Artista Alvo ---\n",
    "print(f\"\\nIniciando preparação para treinamento do artista: '{TARGET_ARTIST}'...\")\n",
    "\n",
    "PROCESSED_DATA_DIR_ARTIST = os.path.join(BASE_OUTPUT_DIR, CLEAN_TARGET_ARTIST_NAME)\n",
    "TOKENIZER_PATH = os.path.join(PROCESSED_DATA_DIR_ARTIST, TOKENIZER_SUBDIR, f'char_tokenizer_{CLEAN_TARGET_ARTIST_NAME}.pkl')\n",
    "X_train_file_path = os.path.join(PROCESSED_DATA_DIR_ARTIST, DATA_SUBDIR, f'X_train_{CLEAN_TARGET_ARTIST_NAME}_char.npy')\n",
    "y_train_file_path = os.path.join(PROCESSED_DATA_DIR_ARTIST, DATA_SUBDIR, f'y_train_{CLEAN_TARGET_ARTIST_NAME}_char.npy')\n",
    "X_val_file_path = os.path.join(PROCESSED_DATA_DIR_ARTIST, DATA_SUBDIR, f'X_val_{CLEAN_TARGET_ARTIST_NAME}_char.npy')\n",
    "y_val_file_path = os.path.join(PROCESSED_DATA_DIR_ARTIST, DATA_SUBDIR, f'y_val_{CLEAN_TARGET_ARTIST_NAME}_char.npy')\n",
    "\n",
    "if not all(os.path.exists(p) for p in [X_train_file_path, y_train_file_path, X_val_file_path, y_val_file_path]):\n",
    "    print(f\"Dados tokenizados para '{TARGET_ARTIST}' não encontrados. Execute o pré-processamento primeiro.\")\n",
    "else:\n",
    "    try:\n",
    "        tokenizer = load_object(TOKENIZER_PATH)\n",
    "        total_chars = load_object(os.path.join(PROCESSED_DATA_DIR_ARTIST, TOKENIZER_SUBDIR, f'vocab_size_{CLEAN_TARGET_ARTIST_NAME}_char.pkl'))\n",
    "        print(f\"Vocabulário de caracteres carregado. Tamanho: {total_chars}\")\n",
    "\n",
    "        train_dataset = LyricsDataset(X_train_file_path, y_train_file_path)\n",
    "        val_dataset = LyricsDataset(X_val_file_path, y_val_file_path)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "        print(f\"Dataset de treino: {len(train_dataset)} amostras, {len(train_loader)} batches.\")\n",
    "        print(f\"Dataset de validação: {len(val_dataset)} amostras, {len(val_loader)} batches.\")\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(e)\n",
    "\n",
    "# --- Hiperparâmetros do Modelo ---\n",
    "EMBEDDING_DIM = 256\n",
    "HIDDEN_DIM = 256\n",
    "N_LAYERS = 4\n",
    "DROPOUT_RATE = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df152fe",
   "metadata": {},
   "source": [
    "### Sem Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cdfbdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CharLSTM(\n",
      "  (embedding): Embedding(36, 256)\n",
      "  (lstm): LSTM(256, 256, num_layers=4, batch_first=True, bidirectional=True)\n",
      "  (dropout_layer): Dropout(p=0.2, inplace=False)\n",
      "  (fc): Linear(in_features=512, out_features=36, bias=True)\n",
      ")\n",
      "Iniciando treinamento para 'ArianaGrande' com estratégia de dropout: 'none'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 2818/2818 [04:53<00:00,  9.60it/s]\n",
      "Epoch 1/10 [Validation]: 100%|██████████| 351/351 [00:13<00:00, 26.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: Train Loss: 1.5494, Train Acc: 0.5353, Val Loss: 1.3719, Val Acc: 0.5837\n",
      "Modelo salvo: Melhor val_loss em 1.3719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 2818/2818 [04:55<00:00,  9.52it/s]\n",
      "Epoch 2/10 [Validation]: 100%|██████████| 351/351 [00:16<00:00, 21.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: Train Loss: 1.1019, Train Acc: 0.6655, Val Loss: 1.2388, Val Acc: 0.6236\n",
      "Modelo salvo: Melhor val_loss em 1.2388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 2818/2818 [05:03<00:00,  9.30it/s]\n",
      "Epoch 3/10 [Validation]: 100%|██████████| 351/351 [00:13<00:00, 26.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: Train Loss: 0.8778, Train Acc: 0.7334, Val Loss: 1.2101, Val Acc: 0.6423\n",
      "Modelo salvo: Melhor val_loss em 1.2101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Train]: 100%|██████████| 2818/2818 [04:52<00:00,  9.65it/s]\n",
      "Epoch 4/10 [Validation]: 100%|██████████| 351/351 [00:12<00:00, 27.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: Train Loss: 0.7146, Train Acc: 0.7834, Val Loss: 1.1789, Val Acc: 0.6602\n",
      "Modelo salvo: Melhor val_loss em 1.1789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 [Train]: 100%|██████████| 2818/2818 [04:51<00:00,  9.66it/s]\n",
      "Epoch 5/10 [Validation]: 100%|██████████| 351/351 [00:13<00:00, 26.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: Train Loss: 0.5961, Train Acc: 0.8191, Val Loss: 1.1791, Val Acc: 0.6742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 [Train]: 100%|██████████| 2818/2818 [04:51<00:00,  9.66it/s]\n",
      "Epoch 6/10 [Validation]: 100%|██████████| 351/351 [00:12<00:00, 27.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: Train Loss: 0.5052, Train Acc: 0.8461, Val Loss: 1.2145, Val Acc: 0.6778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 [Train]: 100%|██████████| 2818/2818 [04:52<00:00,  9.62it/s]\n",
      "Epoch 7/10 [Validation]: 100%|██████████| 351/351 [00:13<00:00, 26.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: Train Loss: 0.4396, Train Acc: 0.8650, Val Loss: 1.2523, Val Acc: 0.6845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 [Train]: 100%|██████████| 2818/2818 [04:52<00:00,  9.63it/s]\n",
      "Epoch 8/10 [Validation]: 100%|██████████| 351/351 [00:12<00:00, 27.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: Train Loss: 0.3890, Train Acc: 0.8801, Val Loss: 1.2992, Val Acc: 0.6896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 [Train]: 100%|██████████| 2818/2818 [05:10<00:00,  9.07it/s]\n",
      "Epoch 9/10 [Validation]: 100%|██████████| 351/351 [00:14<00:00, 24.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: Train Loss: 0.3548, Train Acc: 0.8898, Val Loss: 1.3483, Val Acc: 0.6879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 [Train]: 100%|██████████| 2818/2818 [05:13<00:00,  8.99it/s]\n",
      "Epoch 10/10 [Validation]: 100%|██████████| 351/351 [00:14<00:00, 24.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: Train Loss: 0.3242, Train Acc: 0.8990, Val Loss: 1.3644, Val Acc: 0.6946\n",
      "\n",
      "Histórico de treinamento salvo em: models_by_artist_char_split\\arianagrande\\training_history_arianagrande_strategy_none.pkl\n",
      "\n",
      "Treinamento para 'ArianaGrande' com estratégia 'none' concluído.\n",
      "O melhor modelo foi salvo em: models_by_artist_char_split\\arianagrande\\model_weights_arianagrande_strategy_none_best.pt\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Instancia o modelo LSTM com uma estratégia de dropout específica, executa\n",
    "o loop de treinamento e validação, salva o melhor modelo com base na\n",
    "perda de validação e armazena o histórico completo de treinamento em um\n",
    "arquivo pickle para análise posterior.\n",
    "\"\"\"\n",
    "CURRENT_DROPOUT_STRATEGY = \"none\"\n",
    "\n",
    "model = CharLSTM(\n",
    "    vocab_size=total_chars,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    n_layers=N_LAYERS,\n",
    "    dropout_rate=DROPOUT_RATE,\n",
    "    dropout_strategy=CURRENT_DROPOUT_STRATEGY\n",
    ").to(device)\n",
    "\n",
    "print(model)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "model_save_filename = f\"model_weights_{CLEAN_TARGET_ARTIST_NAME}_strategy_{CURRENT_DROPOUT_STRATEGY}_best.pt\"\n",
    "model_save_filepath = os.path.join(MODEL_DIR_ARTIST, model_save_filename)\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "print(f\"Iniciando treinamento para '{TARGET_ARTIST}' com estratégia de dropout: '{CURRENT_DROPOUT_STRATEGY}'...\")\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Train]\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_predictions += labels.size(0)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "    train_loss = train_loss / len(train_dataset)\n",
    "    train_accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Validation]\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_predictions += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss = val_loss / len(val_dataset)\n",
    "    val_accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}: Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), model_save_filepath)\n",
    "        print(f\"Modelo salvo: Melhor val_loss em {best_val_loss:.4f}\")\n",
    "\n",
    "history = {\n",
    "    'train_loss': train_losses,\n",
    "    'val_loss': val_losses,\n",
    "    'train_accuracy': train_accuracies,\n",
    "    'val_accuracy': val_accuracies,\n",
    "    'dropout_strategy': CURRENT_DROPOUT_STRATEGY\n",
    "}\n",
    "history_filename = f\"training_history_{CLEAN_TARGET_ARTIST_NAME}_strategy_{CURRENT_DROPOUT_STRATEGY}.pkl\"\n",
    "history_filepath = os.path.join(MODEL_DIR_ARTIST, history_filename)\n",
    "with open(history_filepath, 'wb') as f:\n",
    "    pickle.dump(history, f)\n",
    "print(f\"\\nHistórico de treinamento salvo em: {history_filepath}\")\n",
    "\n",
    "print(f\"\\nTreinamento para '{TARGET_ARTIST}' com estratégia '{CURRENT_DROPOUT_STRATEGY}' concluído.\")\n",
    "print(f\"O melhor modelo foi salvo em: {model_save_filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5492fe",
   "metadata": {},
   "source": [
    "### Depois de cada camada densa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6665a7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CharLSTM(\n",
      "  (embedding): Embedding(36, 256)\n",
      "  (lstm): LSTM(256, 256, num_layers=4, batch_first=True, dropout=0.2, bidirectional=True)\n",
      "  (dropout_layer): Dropout(p=0.2, inplace=False)\n",
      "  (fc): Linear(in_features=512, out_features=36, bias=True)\n",
      ")\n",
      "Iniciando treinamento para 'ArianaGrande' com estratégia de dropout: 'between_lstm'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 2827/2827 [12:59<00:00,  3.63it/s]\n",
      "Epoch 1/10 [Validation]: 100%|██████████| 364/364 [00:31<00:00, 11.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: Train Loss: 1.5248, Train Acc: 0.5418, Val Loss: 1.3570, Val Acc: 0.5895\n",
      "Modelo salvo: Melhor val_loss em 1.3570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 2827/2827 [12:56<00:00,  3.64it/s]\n",
      "Epoch 2/10 [Validation]: 100%|██████████| 364/364 [00:32<00:00, 11.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: Train Loss: 1.1012, Train Acc: 0.6639, Val Loss: 1.2299, Val Acc: 0.6276\n",
      "Modelo salvo: Melhor val_loss em 1.2299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 2827/2827 [12:56<00:00,  3.64it/s]\n",
      "Epoch 3/10 [Validation]: 100%|██████████| 364/364 [00:31<00:00, 11.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: Train Loss: 0.9286, Train Acc: 0.7153, Val Loss: 1.1940, Val Acc: 0.6458\n",
      "Modelo salvo: Melhor val_loss em 1.1940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Train]: 100%|██████████| 2827/2827 [13:04<00:00,  3.60it/s]\n",
      "Epoch 4/10 [Validation]: 100%|██████████| 364/364 [00:32<00:00, 11.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: Train Loss: 0.8194, Train Acc: 0.7479, Val Loss: 1.1849, Val Acc: 0.6566\n",
      "Modelo salvo: Melhor val_loss em 1.1849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 [Train]: 100%|██████████| 2827/2827 [13:11<00:00,  3.57it/s]\n",
      "Epoch 5/10 [Validation]: 100%|██████████| 364/364 [00:32<00:00, 11.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: Train Loss: 0.7491, Train Acc: 0.7688, Val Loss: 1.1979, Val Acc: 0.6612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 [Train]: 100%|██████████| 2827/2827 [13:10<00:00,  3.58it/s]\n",
      "Epoch 6/10 [Validation]: 100%|██████████| 364/364 [00:33<00:00, 10.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: Train Loss: 0.6984, Train Acc: 0.7835, Val Loss: 1.1988, Val Acc: 0.6662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 [Train]: 100%|██████████| 2827/2827 [13:18<00:00,  3.54it/s]\n",
      "Epoch 7/10 [Validation]: 100%|██████████| 364/364 [00:32<00:00, 11.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: Train Loss: 0.6610, Train Acc: 0.7951, Val Loss: 1.2160, Val Acc: 0.6704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 [Train]: 100%|██████████| 2827/2827 [12:07<00:00,  3.88it/s]\n",
      "Epoch 8/10 [Validation]: 100%|██████████| 364/364 [00:29<00:00, 12.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: Train Loss: 0.6362, Train Acc: 0.8019, Val Loss: 1.1876, Val Acc: 0.6760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 [Train]: 100%|██████████| 2827/2827 [07:27<00:00,  6.31it/s]\n",
      "Epoch 9/10 [Validation]: 100%|██████████| 364/364 [00:13<00:00, 26.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: Train Loss: 0.6109, Train Acc: 0.8097, Val Loss: 1.2188, Val Acc: 0.6718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 [Train]: 100%|██████████| 2827/2827 [05:23<00:00,  8.73it/s]\n",
      "Epoch 10/10 [Validation]: 100%|██████████| 364/364 [00:16<00:00, 22.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: Train Loss: 0.5958, Train Acc: 0.8143, Val Loss: 1.2061, Val Acc: 0.6772\n",
      "\n",
      "Histórico de treinamento salvo em: models_by_artist_char_split\\arianagrande\\training_history_arianagrande_strategy_between_lstm.pkl\n",
      "\n",
      "Treinamento para 'ArianaGrande' com estratégia 'between_lstm' concluído.\n",
      "O melhor modelo foi salvo em: models_by_artist_char_split\\arianagrande\\model_weights_arianagrande_strategy_between_lstm_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Instancia o modelo LSTM com uma estratégia de dropout específica, executa\n",
    "o loop de treinamento e validação, salva o melhor modelo com base na\n",
    "perda de validação e armazena o histórico completo de treinamento em um\n",
    "arquivo pickle para análise posterior.\n",
    "\"\"\"\n",
    "CURRENT_DROPOUT_STRATEGY = \"between_lstm\"\n",
    "\n",
    "model = CharLSTM(\n",
    "    vocab_size=total_chars,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    n_layers=N_LAYERS,\n",
    "    dropout_rate=DROPOUT_RATE,\n",
    "    dropout_strategy=CURRENT_DROPOUT_STRATEGY\n",
    ").to(device)\n",
    "\n",
    "print(model)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "model_save_filename = f\"model_weights_{CLEAN_TARGET_ARTIST_NAME}_strategy_{CURRENT_DROPOUT_STRATEGY}_best.pt\"\n",
    "model_save_filepath = os.path.join(MODEL_DIR_ARTIST, model_save_filename)\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "print(f\"Iniciando treinamento para '{TARGET_ARTIST}' com estratégia de dropout: '{CURRENT_DROPOUT_STRATEGY}'...\")\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Train]\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_predictions += labels.size(0)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "    train_loss = train_loss / len(train_dataset)\n",
    "    train_accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Validation]\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_predictions += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss = val_loss / len(val_dataset)\n",
    "    val_accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}: Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), model_save_filepath)\n",
    "        print(f\"Modelo salvo: Melhor val_loss em {best_val_loss:.4f}\")\n",
    "\n",
    "history = {\n",
    "    'train_loss': train_losses,\n",
    "    'val_loss': val_losses,\n",
    "    'train_accuracy': train_accuracies,\n",
    "    'val_accuracy': val_accuracies,\n",
    "    'dropout_strategy': CURRENT_DROPOUT_STRATEGY\n",
    "}\n",
    "history_filename = f\"training_history_{CLEAN_TARGET_ARTIST_NAME}_strategy_{CURRENT_DROPOUT_STRATEGY}.pkl\"\n",
    "history_filepath = os.path.join(MODEL_DIR_ARTIST, history_filename)\n",
    "with open(history_filepath, 'wb') as f:\n",
    "    pickle.dump(history, f)\n",
    "print(f\"\\nHistórico de treinamento salvo em: {history_filepath}\")\n",
    "\n",
    "print(f\"\\nTreinamento para '{TARGET_ARTIST}' com estratégia '{CURRENT_DROPOUT_STRATEGY}' concluído.\")\n",
    "print(f\"O melhor modelo foi salvo em: {model_save_filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dc7149",
   "metadata": {},
   "source": [
    "### Antes da camada de saída"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8932a76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CharLSTM(\n",
      "  (embedding): Embedding(36, 256)\n",
      "  (lstm): LSTM(256, 256, num_layers=4, batch_first=True, bidirectional=True)\n",
      "  (dropout_layer): Dropout(p=0.2, inplace=False)\n",
      "  (fc): Linear(in_features=512, out_features=36, bias=True)\n",
      ")\n",
      "Iniciando treinamento para 'ArianaGrande' com estratégia de dropout: 'before_fc'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 2827/2827 [05:23<00:00,  8.73it/s]\n",
      "Epoch 1/10 [Validation]: 100%|██████████| 364/364 [00:13<00:00, 27.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: Train Loss: 1.5346, Train Acc: 0.5407, Val Loss: 1.3476, Val Acc: 0.5914\n",
      "Modelo salvo: Melhor val_loss em 1.3476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 2827/2827 [05:06<00:00,  9.22it/s]\n",
      "Epoch 2/10 [Validation]: 100%|██████████| 364/364 [00:14<00:00, 25.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: Train Loss: 1.1014, Train Acc: 0.6644, Val Loss: 1.2490, Val Acc: 0.6268\n",
      "Modelo salvo: Melhor val_loss em 1.2490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 2827/2827 [05:03<00:00,  9.32it/s]\n",
      "Epoch 3/10 [Validation]: 100%|██████████| 364/364 [00:15<00:00, 23.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: Train Loss: 0.8845, Train Acc: 0.7315, Val Loss: 1.1938, Val Acc: 0.6511\n",
      "Modelo salvo: Melhor val_loss em 1.1938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Train]: 100%|██████████| 2827/2827 [05:13<00:00,  9.01it/s]\n",
      "Epoch 4/10 [Validation]: 100%|██████████| 364/364 [00:13<00:00, 26.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: Train Loss: 0.7276, Train Acc: 0.7788, Val Loss: 1.1956, Val Acc: 0.6642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 [Train]: 100%|██████████| 2827/2827 [05:57<00:00,  7.91it/s]\n",
      "Epoch 5/10 [Validation]: 100%|██████████| 364/364 [00:13<00:00, 26.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: Train Loss: 0.6135, Train Acc: 0.8131, Val Loss: 1.2070, Val Acc: 0.6689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 [Train]: 100%|██████████| 2827/2827 [05:08<00:00,  9.17it/s]\n",
      "Epoch 6/10 [Validation]: 100%|██████████| 364/364 [00:15<00:00, 24.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: Train Loss: 0.5334, Train Acc: 0.8373, Val Loss: 1.2041, Val Acc: 0.6751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 [Train]: 100%|██████████| 2827/2827 [05:14<00:00,  9.00it/s]\n",
      "Epoch 7/10 [Validation]: 100%|██████████| 364/364 [00:16<00:00, 22.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: Train Loss: 0.4698, Train Acc: 0.8558, Val Loss: 1.2417, Val Acc: 0.6836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 [Train]: 100%|██████████| 2827/2827 [05:15<00:00,  8.97it/s]\n",
      "Epoch 8/10 [Validation]: 100%|██████████| 364/364 [00:14<00:00, 25.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: Train Loss: 0.4261, Train Acc: 0.8686, Val Loss: 1.2900, Val Acc: 0.6854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 [Train]: 100%|██████████| 2827/2827 [05:18<00:00,  8.87it/s]\n",
      "Epoch 9/10 [Validation]: 100%|██████████| 364/364 [00:13<00:00, 26.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: Train Loss: 0.3929, Train Acc: 0.8779, Val Loss: 1.3158, Val Acc: 0.6909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 [Train]: 100%|██████████| 2827/2827 [05:03<00:00,  9.32it/s]\n",
      "Epoch 10/10 [Validation]: 100%|██████████| 364/364 [00:14<00:00, 25.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: Train Loss: 0.3658, Train Acc: 0.8864, Val Loss: 1.3235, Val Acc: 0.6901\n",
      "\n",
      "Histórico de treinamento salvo em: models_by_artist_char_split\\arianagrande\\training_history_arianagrande_strategy_before_fc.pkl\n",
      "\n",
      "Treinamento para 'ArianaGrande' com estratégia 'before_fc' concluído.\n",
      "O melhor modelo foi salvo em: models_by_artist_char_split\\arianagrande\\model_weights_arianagrande_strategy_before_fc_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Instancia o modelo LSTM com uma estratégia de dropout específica, executa\n",
    "o loop de treinamento e validação, salva o melhor modelo com base na\n",
    "perda de validação e armazena o histórico completo de treinamento em um\n",
    "arquivo pickle para análise posterior.\n",
    "\"\"\"\n",
    "CURRENT_DROPOUT_STRATEGY = \"before_fc\"\n",
    "\n",
    "model = CharLSTM(\n",
    "    vocab_size=total_chars,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    n_layers=N_LAYERS,\n",
    "    dropout_rate=DROPOUT_RATE,\n",
    "    dropout_strategy=CURRENT_DROPOUT_STRATEGY\n",
    ").to(device)\n",
    "\n",
    "print(model)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "model_save_filename = f\"model_weights_{CLEAN_TARGET_ARTIST_NAME}_strategy_{CURRENT_DROPOUT_STRATEGY}_best.pt\"\n",
    "model_save_filepath = os.path.join(MODEL_DIR_ARTIST, model_save_filename)\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "print(f\"Iniciando treinamento para '{TARGET_ARTIST}' com estratégia de dropout: '{CURRENT_DROPOUT_STRATEGY}'...\")\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Train]\"):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_predictions += labels.size(0)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "    train_loss = train_loss / len(train_dataset)\n",
    "    train_accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Validation]\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_predictions += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "    val_loss = val_loss / len(val_dataset)\n",
    "    val_accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}: Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.4f}\")\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), model_save_filepath)\n",
    "        print(f\"Modelo salvo: Melhor val_loss em {best_val_loss:.4f}\")\n",
    "\n",
    "history = {\n",
    "    'train_loss': train_losses,\n",
    "    'val_loss': val_losses,\n",
    "    'train_accuracy': train_accuracies,\n",
    "    'val_accuracy': val_accuracies,\n",
    "    'dropout_strategy': CURRENT_DROPOUT_STRATEGY\n",
    "}\n",
    "history_filename = f\"training_history_{CLEAN_TARGET_ARTIST_NAME}_strategy_{CURRENT_DROPOUT_STRATEGY}.pkl\"\n",
    "history_filepath = os.path.join(MODEL_DIR_ARTIST, history_filename)\n",
    "with open(history_filepath, 'wb') as f:\n",
    "    pickle.dump(history, f)\n",
    "print(f\"\\nHistórico de treinamento salvo em: {history_filepath}\")\n",
    "\n",
    "print(f\"\\nTreinamento para '{TARGET_ARTIST}' com estratégia '{CURRENT_DROPOUT_STRATEGY}' concluído.\")\n",
    "print(f\"O melhor modelo foi salvo em: {model_save_filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c26664",
   "metadata": {},
   "source": [
    "## Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cfcdad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 'wordnet' NLTK package...\n",
      "Usando dispositivo: cuda\n",
      "Object loaded from: processed_data_by_artist_char_split\\arianagrande\\tokenizers\\char_tokenizer_arianagrande.pkl\n",
      "Object loaded from: processed_data_by_artist_char_split\\arianagrande\\tokenizers\\vocab_size_arianagrande_char.pkl\n",
      "Vocabulary loaded. Vocabulary size: 36\n",
      "Test dataset with 45029 samples, 352 batches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\gabri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of existing word vocabulary in artist's corpus (for metrics): 4174\n",
      "\n",
      "Generating prompts and targets for evaluation from 29 artist test songs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating prompts and targets: 100%|██████████| 29/29 [00:00<00:00, 510.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total prompts and targets generated for word-level evaluation: 9916\n",
      "\n",
      "Performing POS Tagging of true words...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "POS Tagging true words: 100%|██████████| 10/10 [00:03<00:00,  2.91it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Define funções para avaliação do modelo (perda, acurácia, geração de texto e\n",
    "métricas de qualidade). Carrega os dados de teste, o tokenizador e os recursos\n",
    "linguísticos (NLTK, spaCy). Prepara os prompts e as palavras-alvo para a\n",
    "avaliação qualitativa e quantitativa do modelo treinado.\n",
    "\"\"\"\n",
    "# --- Funções Específicas para Avaliação ---\n",
    "def evaluate_model_loss_acc(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(data_loader, desc=\"Avaliando Perda/Acurácia\"):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_samples += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "    avg_loss = total_loss / total_samples\n",
    "    accuracy = correct_predictions / total_samples\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def generate_next_word_from_prompt_eval(model, tokenizer, prompt_text, sequence_length, device, max_chars_word=25):\n",
    "    model.eval()\n",
    "    current_sequence_str = prompt_text\n",
    "    generated_word_chars = []\n",
    "    word_delimiters = [' ', '.', ',', '!', '?', ';', ':']\n",
    "    started_word = False\n",
    "\n",
    "    for _ in range(max_chars_word):\n",
    "        tokenized_input = tokenizer.texts_to_sequences(current_sequence_str)\n",
    "        if not tokenized_input or all(t == 0 for t in tokenized_input):\n",
    "            break\n",
    "        input_tensor = torch.tensor(tokenized_input, dtype=torch.long).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            predictions = model(input_tensor)\n",
    "        next_char_id = torch.argmax(predictions.squeeze(0), dim=-1).item()\n",
    "        next_char = tokenizer.int_to_char.get(next_char_id, '')\n",
    "\n",
    "        if not started_word:\n",
    "            if next_char.isspace() or next_char in word_delimiters:\n",
    "                current_sequence_str = current_sequence_str[1:] + next_char\n",
    "                continue\n",
    "            else:\n",
    "                started_word = True\n",
    "                generated_word_chars.append(next_char)\n",
    "        elif next_char in word_delimiters:\n",
    "            break\n",
    "        else:\n",
    "            generated_word_chars.append(next_char)\n",
    "        current_sequence_str = current_sequence_str[1:] + next_char\n",
    "    return \"\".join(generated_word_chars).strip()\n",
    "\n",
    "def calculate_text_quality_metrics(text_to_analyze, reference_words_set):\n",
    "    words = nltk.word_tokenize(text_to_analyze.lower())\n",
    "    metrics = {\n",
    "        'total_words': len(words), 'unique_words': 0, 'ttr': 0.0,\n",
    "        'existing_words_count': 0, 'existence_rate': 0.0, 'repetition_rate_words': 0.0,\n",
    "        'repetition_rate_3grams_char': 0.0\n",
    "    }\n",
    "    if not words:\n",
    "        return metrics\n",
    "\n",
    "    unique_words = set(words)\n",
    "    metrics['unique_words'] = len(unique_words)\n",
    "    metrics['ttr'] = len(unique_words) / len(words)\n",
    "    \n",
    "    existing_words_in_generated = sum(1 for word in unique_words if word in reference_words_set)\n",
    "    metrics['existing_words_count'] = existing_words_in_generated\n",
    "    metrics['existence_rate'] = existing_words_in_generated / len(unique_words) if unique_words else 0.0\n",
    "    metrics['repetition_rate_words'] = (len(words) - len(unique_words)) / len(words) if words else 0.0\n",
    "\n",
    "    char_3grams = [text_to_analyze[i:i+3] for i in range(len(text_to_analyze) - 2)]\n",
    "    if char_3grams:\n",
    "        metrics['repetition_rate_3grams_char'] = (len(char_3grams) - len(set(char_3grams))) / len(char_3grams)\n",
    "    return metrics\n",
    "\n",
    "# --- Carregamento e Preparação dos Dados para Avaliação ---\n",
    "try:\n",
    "    tokenizer = load_object(TOKENIZER_PATH)\n",
    "    total_chars = load_object(os.path.join(PROCESSED_DATA_DIR_ARTIST, TOKENIZER_SUBDIR, f'vocab_size_{CLEAN_TARGET_ARTIST_NAME}_char.pkl'))\n",
    "    print(f\"Tokenizador carregado. Tamanho do vocabulário: {total_chars}\")\n",
    "\n",
    "    X_test_file_path = os.path.join(PROCESSED_DATA_DIR_ARTIST, DATA_SUBDIR, f'X_test_{CLEAN_TARGET_ARTIST_NAME}_char.npy')\n",
    "    y_test_file_path = os.path.join(PROCESSED_DATA_DIR_ARTIST, DATA_SUBDIR, f'y_test_{CLEAN_TARGET_ARTIST_NAME}_char.npy')\n",
    "    \n",
    "    test_dataset = LyricsDataset(X_test_file_path, y_test_file_path)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    print(f\"Dataset de teste com {len(test_dataset)} amostras, {len(test_loader)} batches.\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(e)\n",
    "\n",
    "# --- Preparação dos Prompts e Alvos para Avaliação de Nível de Palavra ---\n",
    "prompts_for_eval = []\n",
    "true_next_words = []\n",
    "true_next_pos_tags = []\n",
    "existing_words_in_corpus = set()\n",
    "ARTIST_LYRICS_CLEAN_ALL_FOR_VOCAB = []\n",
    "\n",
    "try:\n",
    "    df_artist_full = pd.read_csv(os.path.join(CSV_FOLDER_PATH, f'{TARGET_ARTIST}.csv'), usecols=['Lyric'])\n",
    "    for lyric_val in df_artist_full['Lyric']:\n",
    "        cleaned_lyric = clean_text(lyric_val)\n",
    "        if cleaned_lyric and PLACEHOLDER_PHRASE not in cleaned_lyric:\n",
    "            ARTIST_LYRICS_CLEAN_ALL_FOR_VOCAB.append(cleaned_lyric)\n",
    "            existing_words_in_corpus.update(nltk.word_tokenize(cleaned_lyric))\n",
    "    print(f\"Tamanho do vocabulário de palavras no corpus do artista: {len(existing_words_in_corpus)}\")\n",
    "\n",
    "    random.seed(RANDOM_SEED)\n",
    "    random.shuffle(ARTIST_LYRICS_CLEAN_ALL_FOR_VOCAB)\n",
    "    num_train = int(len(ARTIST_LYRICS_CLEAN_ALL_FOR_VOCAB) * TRAIN_SPLIT)\n",
    "    num_val = int(len(ARTIST_LYRICS_CLEAN_ALL_FOR_VOCAB) * VAL_SPLIT)\n",
    "    ARTIST_LYRICS_FOR_TEST_PROMPTS = ARTIST_LYRICS_CLEAN_ALL_FOR_VOCAB[num_train + num_val:]\n",
    "    \n",
    "    print(f\"\\nGerando prompts de {len(ARTIST_LYRICS_FOR_TEST_PROMPTS)} músicas de teste do artista...\")\n",
    "    for lyric_text in tqdm(ARTIST_LYRICS_FOR_TEST_PROMPTS, desc=\"Gerando prompts e alvos\"):\n",
    "        tokenized_full_lyric = nltk.word_tokenize(lyric_text)\n",
    "        for i in range(1, len(tokenized_full_lyric)):\n",
    "            target_word = tokenized_full_lyric[i]\n",
    "            context_string = \" \".join(tokenized_full_lyric[:i]) + \" \"\n",
    "            final_prompt = (' ' * (SEQUENCE_LENGTH - len(context_string)) + context_string)[-SEQUENCE_LENGTH:]\n",
    "            if target_word:\n",
    "                prompts_for_eval.append(final_prompt)\n",
    "                true_next_words.append(target_word)\n",
    "    \n",
    "    print(f\"Total de prompts para avaliação de nível de palavra gerados: {len(prompts_for_eval)}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao preparar dados de nível de palavra para avaliação: {e}\")\n",
    "\n",
    "# --- Carregamento do spaCy e Geração de POS Tags ---\n",
    "nlp = None\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    if true_next_words and nlp:\n",
    "        print(\"\\nExecutando POS Tagging nas palavras alvo...\")\n",
    "        docs = nlp.pipe(true_next_words, batch_size=1000)\n",
    "        true_next_pos_tags = [doc[0].pos_ if doc and doc[0] else \"UNKNOWN\" for doc in tqdm(docs, total=len(true_next_words), desc=\"POS Tagging\")]\n",
    "    else:\n",
    "        print(\"Nenhuma palavra alvo para POS tagging ou modelo spaCy não carregado.\")\n",
    "except OSError:\n",
    "    print(\"Modelo spaCy 'en_core_web_sm' não encontrado. Baixando...\")\n",
    "    spacy.cli.download(\"en_core_web_sm\")\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    if true_next_words and nlp:\n",
    "        print(\"\\nExecutando POS Tagging após download...\")\n",
    "        docs = nlp.pipe(true_next_words, batch_size=1000)\n",
    "        true_next_pos_tags = [doc[0].pos_ if doc and doc[0] else \"UNKNOWN\" for doc in tqdm(docs, total=len(true_next_words), desc=\"POS Tagging\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692f5013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 'wordnet' NLTK package...\n",
      "Using device: cuda\n",
      "Object loaded from: processed_data_by_artist_char_split\\arianagrande\\tokenizers\\char_tokenizer_arianagrande.pkl\n",
      "Object loaded from: processed_data_by_artist_char_split\\arianagrande\\tokenizers\\vocab_size_arianagrande_char.pkl\n",
      "Vocabulary loaded. Vocabulary size: 36\n",
      "Test dataset with 45029 samples, 352 batches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\gabri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of existing word vocabulary in artist's corpus (for metrics): 4174\n",
      "Total 29 songs in the artist's test set for generation.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Define funções avançadas para avaliação de qualidade de texto, incluindo\n",
    "métricas de diversidade (Distinct-N) e uma função de geração de texto\n",
    "controlada por contagem de palavras e temperatura. Em seguida, carrega os\n",
    "componentes e prepara o conjunto de teste do artista para a avaliação.\n",
    "\"\"\"\n",
    "# --- Novas Funções para Métricas de Qualidade de Texto ---\n",
    "def get_word_ngrams(text, n):\n",
    "    words = nltk.word_tokenize(text.lower())\n",
    "    if len(words) < n:\n",
    "        return []\n",
    "    return list(nltk.ngrams(words, n))\n",
    "\n",
    "def calculate_distinct_n_ratio(text, n):\n",
    "    ngrams = get_word_ngrams(text, n)\n",
    "    if not ngrams:\n",
    "        return 0.0\n",
    "    unique_ngrams = set(ngrams)\n",
    "    return len(unique_ngrams) / len(ngrams)\n",
    "\n",
    "def calculate_text_quality_metrics_updated(text_to_analyze, reference_words_set):\n",
    "    words = nltk.word_tokenize(text_to_analyze.lower())\n",
    "    metrics = {\n",
    "        'total_words': len(words), 'unique_words': 0, 'ttr': 0.0,\n",
    "        'distinct_1_ratio': 0.0, 'distinct_2_ratio': 0.0, 'distinct_3_ratio': 0.0,\n",
    "        'repetition_rate_words': 0.0, 'repetition_rate_bigrams': 0.0, 'repetition_rate_trigrams': 0.0,\n",
    "        'existing_words_count': 0, 'existence_rate': 0.0,\n",
    "    }\n",
    "    if not words:\n",
    "        return metrics\n",
    "\n",
    "    unique_words = set(words)\n",
    "    metrics['unique_words'] = len(unique_words)\n",
    "    \n",
    "    metrics['ttr'] = calculate_distinct_n_ratio(text_to_analyze, 1)\n",
    "    metrics['distinct_1_ratio'] = metrics['ttr']\n",
    "    metrics['repetition_rate_words'] = 1 - metrics['distinct_1_ratio']\n",
    "\n",
    "    metrics['distinct_2_ratio'] = calculate_distinct_n_ratio(text_to_analyze, 2)\n",
    "    metrics['repetition_rate_bigrams'] = 1 - metrics['distinct_2_ratio']\n",
    "\n",
    "    metrics['distinct_3_ratio'] = calculate_distinct_n_ratio(text_to_analyze, 3)\n",
    "    metrics['repetition_rate_trigrams'] = 1 - metrics['distinct_3_ratio']\n",
    "\n",
    "    existing_words_in_generated = sum(1 for word in unique_words if word in reference_words_set)\n",
    "    metrics['existing_words_count'] = existing_words_in_generated\n",
    "    metrics['existence_rate'] = existing_words_in_generated / len(unique_words) if unique_words else 0.0\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def generate_text_by_word_count(model, tokenizer, seed_text, target_word_count, temperature=0.8, sequence_length=SEQUENCE_LENGTH, device=device, max_chars_per_word=25):\n",
    "    model.eval()\n",
    "    processed_seed_text = clean_text(seed_text)\n",
    "    \n",
    "    if len(processed_seed_text) < sequence_length:\n",
    "        processed_seed_text = ' ' * (sequence_length - len(processed_seed_text)) + processed_seed_text\n",
    "    elif len(processed_seed_text) > sequence_length:\n",
    "        processed_seed_text = processed_seed_text[-sequence_length:]\n",
    "    \n",
    "    generated_text = processed_seed_text\n",
    "    current_word_count = len(nltk.word_tokenize(processed_seed_text))\n",
    "    pbar = tqdm(total=target_word_count, initial=current_word_count, desc=\"Gerando palavras\")\n",
    "    \n",
    "    max_chars_to_generate_total = target_word_count * max_chars_per_word * 2\n",
    "    chars_generated = 0\n",
    "    \n",
    "    while current_word_count < target_word_count and chars_generated < max_chars_to_generate_total:\n",
    "        current_sequence_str = generated_text[-sequence_length:]\n",
    "        tokenized_input = tokenizer.texts_to_sequences(current_sequence_str)\n",
    "\n",
    "        if not tokenized_input or all(t == 0 for t in tokenized_input):\n",
    "            break\n",
    "\n",
    "        input_tensor = torch.tensor(tokenized_input, dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            predictions = model(input_tensor).squeeze(0)\n",
    "        \n",
    "        if temperature <= 0:\n",
    "            next_char_id = torch.argmax(predictions, dim=-1).item()\n",
    "        else:\n",
    "            probabilities = torch.softmax(predictions / temperature, dim=-1)\n",
    "            next_char_id = torch.multinomial(probabilities, num_samples=1).item()\n",
    "        \n",
    "        next_char = tokenizer.int_to_char.get(next_char_id, '')\n",
    "        generated_text += next_char\n",
    "        chars_generated += 1\n",
    "\n",
    "        if chars_generated % 50 == 0 or (next_char.isspace() or next_char in '!?,.'):\n",
    "            new_word_count = len(nltk.word_tokenize(generated_text))\n",
    "            if new_word_count > current_word_count:\n",
    "                pbar.update(new_word_count - current_word_count)\n",
    "                current_word_count = new_word_count\n",
    "    \n",
    "    pbar.close()\n",
    "    if len(nltk.word_tokenize(generated_text)) < target_word_count:\n",
    "        print(f\"\\nAtenção: Geração interrompida antes de atingir {target_word_count} palavras.\")\n",
    "\n",
    "    return generated_text\n",
    "\n",
    "# --- Preparação dos Dados e Recursos para Avaliação ---\n",
    "CSV_FILE_PATH_TARGET_ARTIST = os.path.join(CSV_FOLDER_PATH, f'{TARGET_ARTIST}.csv')\n",
    "try:\n",
    "    tokenizer = load_object(TOKENIZER_PATH)\n",
    "    total_chars = load_object(os.path.join(PROCESSED_DATA_DIR_ARTIST, TOKENIZER_SUBDIR, f'vocab_size_{CLEAN_TARGET_ARTIST_NAME}_char.pkl'))\n",
    "    print(f\"Tokenizador carregado. Tamanho do vocabulário: {total_chars}\")\n",
    "\n",
    "    X_test_file_path = os.path.join(PROCESSED_DATA_DIR_ARTIST, DATA_SUBDIR, f'X_test_{CLEAN_TARGET_ARTIST_NAME}_char.npy')\n",
    "    y_test_file_path = os.path.join(PROCESSED_DATA_DIR_ARTIST, DATA_SUBDIR, f'y_test_{CLEAN_TARGET_ARTIST_NAME}_char.npy')\n",
    "    test_dataset = LyricsDataset(X_test_file_path, y_test_file_path)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    print(f\"Dataset de teste com {len(test_dataset)} amostras, {len(test_loader)} batches.\")\n",
    "\n",
    "    ARTIST_LYRICS_CLEAN_ALL_FOR_PROMPTS = []\n",
    "    existing_words_in_corpus = set()\n",
    "    df_target_artist_full = pd.read_csv(CSV_FILE_PATH_TARGET_ARTIST, usecols=['Lyric'])\n",
    "    for lyric_val in df_target_artist_full['Lyric']:\n",
    "        cleaned_lyric = clean_text(lyric_val)\n",
    "        if cleaned_lyric and PLACEHOLDER_PHRASE not in cleaned_lyric:\n",
    "            ARTIST_LYRICS_CLEAN_ALL_FOR_PROMPTS.append(cleaned_lyric)\n",
    "            existing_words_in_corpus.update(nltk.word_tokenize(cleaned_lyric))\n",
    "    \n",
    "    print(f\"Tamanho do vocabulário de palavras do artista (para métricas): {len(existing_words_in_corpus)}\")\n",
    "    \n",
    "    random.seed(RANDOM_SEED)\n",
    "    random.shuffle(ARTIST_LYRICS_CLEAN_ALL_FOR_PROMPTS)\n",
    "    num_total_artist_lyrics = len(ARTIST_LYRICS_CLEAN_ALL_FOR_PROMPTS)\n",
    "    num_train = int(num_total_artist_lyrics * TRAIN_SPLIT)\n",
    "    num_val = int(num_total_artist_lyrics * VAL_SPLIT)\n",
    "    TEST_LYRICS_ARTIST_FINAL_SONGS = ARTIST_LYRICS_CLEAN_ALL_FOR_PROMPTS[num_train + num_val:]\n",
    "    print(f\"Total de {len(TEST_LYRICS_ARTIST_FINAL_SONGS)} músicas no conjunto de teste do artista para geração.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao carregar dados para avaliação: {e}\")\n",
    "\n",
    "nlp = None\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except OSError:\n",
    "    print(\"Modelo spaCy 'en_core_web_sm' não encontrado. Baixando...\")\n",
    "    spacy.cli.download(\"en_core_web_sm\")\n",
    "    nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacbd532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- AVALIAÇÃO: Modelo com Dropout 'none' ---\n",
      "Model 'model_weights_arianagrande_strategy_none_best.pt' loaded from: models_by_artist_char_split\\arianagrande\\model_weights_arianagrande_strategy_none_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Loss/Acc: 100%|██████████| 352/352 [00:13<00:00, 25.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Resultados de Avaliação no Conjunto de TESTE (Caracter): 'ArianaGrande' (Dropout: none) ---\n",
      "Test Loss (Cross-Entropy): 0.7584\n",
      "Test Accuracy (Next Character): 0.7753\n",
      "Perplexity: 2.1349\n",
      "-----------------------------------------------------\n",
      "\n",
      "--- Avaliação de Geração de Músicas (Música a Música) para 'ArianaGrande' (Dropout: none) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating words: 4it [00:00,  9.30it/s]     | 0/29 [00:00<?, ?it/s]\n",
      "Generating words: 100%|██████████| 673/673 [00:46<00:00, 14.41it/s]2.33it/s]\n",
      "Generating words: 100%|██████████| 775/775 [01:00<00:00, 12.84it/s]7.67s/it]\n",
      "Generating words: 520it [00:56,  9.21it/s]   | 3/29 [01:47<18:27, 42.60s/it]\n",
      "Generating words: 100%|██████████| 510/510 [00:45<00:00, 11.28it/s]8.08s/it]\n",
      "Generating words: 100%|██████████| 402/402 [00:36<00:00, 11.06it/s]7.05s/it]\n",
      "Generating words: 100%|██████████| 372/372 [00:36<00:00, 10.14it/s]3.41s/it]\n",
      "Generating words: 100%|██████████| 381/381 [00:33<00:00, 11.35it/s]1.22s/it]\n",
      "Generating words: 100%|██████████| 14/14 [00:02<00:00,  5.46it/s] 38.79s/it]\n",
      "Generating words: 100%|██████████| 316/316 [00:30<00:00, 10.22it/s]7.47s/it]\n",
      "Generating words: 100%|██████████| 526/526 [00:51<00:00, 10.20it/s]28.54s/it]\n",
      "Generating words: 100%|██████████| 13/13 [00:02<00:00,  6.21it/s], 35.60s/it]\n",
      "Generating words: 100%|██████████| 337/337 [00:33<00:00, 10.04it/s]25.41s/it]\n",
      "Generating words: 100%|██████████| 89/89 [00:09<00:00,  9.53it/s], 27.88s/it]\n",
      "Generating words: 100%|██████████| 336/336 [00:34<00:00,  9.61it/s]22.28s/it]\n",
      "Generating words: 100%|██████████| 23/23 [00:02<00:00,  9.59it/s], 26.11s/it]\n",
      "Generating words: 100%|██████████| 494/494 [00:32<00:00, 15.03it/s]18.97s/it]\n",
      "Generating words: 100%|██████████| 443/443 [00:36<00:00, 12.22it/s]23.16s/it]\n",
      "Generating words: 100%|██████████| 45/45 [00:04<00:00,  9.06it/s], 27.11s/it]\n",
      "Generating words: 100%|██████████| 268/268 [00:23<00:00, 11.51it/s]20.46s/it]\n",
      "Generating words: 100%|██████████| 383/383 [00:35<00:00, 10.82it/s]21.31s/it]\n",
      "Generating words: 100%|██████████| 477/477 [00:53<00:00,  8.96it/s]25.54s/it]\n",
      "Generating words: 100%|██████████| 154/154 [00:14<00:00, 10.86it/s]33.86s/it]\n",
      "Generating words: 100%|██████████| 463/463 [00:49<00:00,  9.45it/s]27.96s/it]\n",
      "Generating words: 360it [00:35, 10.15it/s]█▎ | 24/29 [12:12<02:51, 34.28s/it]\n",
      "Generating words: 100%|██████████| 261/261 [00:25<00:00, 10.11it/s]34.65s/it]\n",
      "Generating words: 100%|██████████| 153/153 [00:13<00:00, 10.93it/s]32.00s/it]\n",
      "Generating words: 100%|██████████| 567/567 [00:58<00:00,  9.76it/s]26.60s/it]\n",
      "Generating words: 100%|██████████| 19/19 [00:02<00:00,  8.13it/s], 36.06s/it]\n",
      "Generating & Evaluating none: 100%|██████████| 29/29 [14:28<00:00, 29.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- MÉDIAS DAS MÉTRICAS DE GERAÇÃO (Dropout: none) ---\n",
      "\n",
      "--- Letras Geradas (Média) ---\n",
      "Total Words (Avg): 344.24\n",
      "Unique Words (Avg): 138.28\n",
      "TTR (Distinct-1 Ratio) (Avg): 0.4961\n",
      "Repetition Rate (1-Distinct-1) (Avg): 0.5039\n",
      "Distinct-2 Ratio (Bigrams) (Avg): 0.8432\n",
      "Repetition Rate (1-Distinct-2) (Bigrams) (Avg): 0.1568\n",
      "Distinct-3 Ratio (Trigrams) (Avg): 0.9225\n",
      "Repetition Rate (1-Distinct-3) (Trigrams) (Avg): 0.0775\n",
      "Generated Unique Words Existing in Corpus (Avg): 125.97\n",
      "Existence Rate (Generated Unique Words) (Avg): 0.92%\n",
      "-----------------------------------------------------\n",
      "\n",
      "--- Letras Originais do Teste (Média) ---\n",
      "Total Words (Avg): 342.93\n",
      "Unique Words (Avg): 91.79\n",
      "TTR (Distinct-1 Ratio) (Avg): 0.3644\n",
      "Repetition Rate (1-Distinct-1) (Avg): 0.6356\n",
      "Distinct-2 Ratio (Bigrams) (Avg): 0.5176\n",
      "Repetition Rate (1-Distinct-2) (Bigrams) (Avg): 0.4824\n",
      "Distinct-3 Ratio (Trigrams) (Avg): 0.5837\n",
      "Repetition Rate (1-Distinct-3) (Trigrams) (Avg): 0.4163\n",
      "Actual Unique Words Existing in Corpus (Avg): 91.79\n",
      "Existence Rate (Actual Unique Words) (Avg): 1.00%\n",
      "-----------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Executa a avaliação completa para um modelo pré-treinado com uma estratégia\n",
    "de dropout específica. Carrega os pesos do modelo, calcula a perda e a\n",
    "acurácia no conjunto de teste e, em seguida, itera sobre cada música de\n",
    "teste para gerar uma nova versão. Por fim, calcula e exibe as médias das\n",
    "métricas de qualidade de texto para as letras geradas e as originais,\n",
    "permitindo uma comparação direta.\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n--- AVALIAÇÃO: Modelo com Dropout 'none' ---\")\n",
    "\n",
    "CURRENT_DROPOUT_STRATEGY = \"none\" \n",
    "MODEL_SAVE_FILENAME = f\"model_weights_{CLEAN_TARGET_ARTIST_NAME}_strategy_{CURRENT_DROPOUT_STRATEGY}_best.pt\"\n",
    "model_save_filepath = os.path.join(MODEL_DIR_ARTIST, MODEL_SAVE_FILENAME)\n",
    "\n",
    "if not os.path.exists(model_save_filepath):\n",
    "    print(f\"Error: Trained model '{model_save_filepath}' for strategy '{CURRENT_DROPOUT_STRATEGY}' not found. Please train this model first.\")\n",
    "    exit() \n",
    "\n",
    "model = CharLSTM(\n",
    "    vocab_size=total_chars,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    n_layers=N_LAYERS,\n",
    "    dropout_rate=DROPOUT_RATE,\n",
    "    dropout_strategy=CURRENT_DROPOUT_STRATEGY \n",
    ").to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(model_save_filepath, map_location=device))\n",
    "print(f\"Model '{MODEL_SAVE_FILENAME}' loaded from: {model_save_filepath}\")\n",
    "\n",
    "# --- Calcular Loss e Acurácia de Caractere (no conjunto de teste tokenizado) ---\n",
    "test_loss, test_accuracy = evaluate_model_loss_acc(model, test_loader, criterion, device)\n",
    "perplexity = np.exp(test_loss) if not np.isnan(test_loss) else float('nan')\n",
    "\n",
    "print(f\"\\n--- Avaliação de Geração de Músicas (Música a Música) para '{TARGET_ARTIST}' (Dropout: {CURRENT_DROPOUT_STRATEGY}) ---\")\n",
    "\n",
    "all_generated_lyrics_metrics = []\n",
    "all_actual_lyrics_metrics = []\n",
    "if not TEST_LYRICS_ARTIST_FINAL_SONGS:\n",
    "    print(\"WARNING: No artist test songs available for generation. Skipping song-by-song evaluation.\")\n",
    "else:\n",
    "    for i, original_lyric_text in enumerate(tqdm(TEST_LYRICS_ARTIST_FINAL_SONGS, desc=f\"Generating & Evaluating {CURRENT_DROPOUT_STRATEGY}\")):\n",
    "        original_lyric_words = nltk.word_tokenize(original_lyric_text)\n",
    "        target_word_count = len(original_lyric_words)\n",
    "\n",
    "        if target_word_count < 20: \n",
    "            target_word_count = 20\n",
    "        \n",
    "        if len(original_lyric_text) < SEQUENCE_LENGTH:\n",
    "            seed_text = ' ' * (SEQUENCE_LENGTH - len(original_lyric_text)) + original_lyric_text\n",
    "        else:\n",
    "            seed_text = original_lyric_text[:SEQUENCE_LENGTH]\n",
    "\n",
    "        # Gerar a Música\n",
    "        generated_lyric_text = generate_text_by_word_count(model, tokenizer, seed_text, \n",
    "                                                           target_word_count, \n",
    "                                                           temperature=0.8, \n",
    "                                                           sequence_length=SEQUENCE_LENGTH, \n",
    "                                                           device=device)\n",
    "        \n",
    "        # Calcular Métricas para a Letra Gerada\n",
    "        metrics_generated = calculate_text_quality_metrics_updated(generated_lyric_text, existing_words_in_corpus)\n",
    "        all_generated_lyrics_metrics.append(metrics_generated)\n",
    "\n",
    "        # Calcular Métricas para a Letra Original (para comparação)\n",
    "        metrics_actual = calculate_text_quality_metrics_updated(original_lyric_text, existing_words_in_corpus)\n",
    "        all_actual_lyrics_metrics.append(metrics_actual)\n",
    "\n",
    "    # Calcular a Média das Métricas\n",
    "    if all_generated_lyrics_metrics:\n",
    "        avg_generated_metrics = {k: np.mean([d[k] for d in all_generated_lyrics_metrics if d[k] is not None]) for k in all_generated_lyrics_metrics[0]}\n",
    "        avg_actual_metrics = {k: np.mean([d[k] for d in all_actual_lyrics_metrics if d[k] is not None]) for k in all_actual_lyrics_metrics[0]}\n",
    "        \n",
    "        print(f\"\\n--- MÉDIAS DAS MÉTRICAS DE GERAÇÃO (Dropout: {CURRENT_DROPOUT_STRATEGY}) ---\")\n",
    "        print(\"\\n--- Letras Geradas (Média) ---\")\n",
    "        print(f\"Total Words (Avg): {avg_generated_metrics['total_words']:.2f}\")\n",
    "        print(f\"Unique Words (Avg): {avg_generated_metrics['unique_words']:.2f}\")\n",
    "        print(f\"TTR (Distinct-1 Ratio) (Avg): {avg_generated_metrics['distinct_1_ratio']:.4f}\")\n",
    "        print(f\"Repetition Rate (1-Distinct-1) (Avg): {avg_generated_metrics['repetition_rate_words']:.4f}\")\n",
    "        print(f\"Distinct-2 Ratio (Bigrams) (Avg): {avg_generated_metrics['distinct_2_ratio']:.4f}\")\n",
    "        print(f\"Repetition Rate (1-Distinct-2) (Bigrams) (Avg): {avg_generated_metrics['repetition_rate_bigrams']:.4f}\")\n",
    "        print(f\"Distinct-3 Ratio (Trigrams) (Avg): {avg_generated_metrics['distinct_3_ratio']:.4f}\")\n",
    "        print(f\"Repetition Rate (1-Distinct-3) (Trigrams) (Avg): {avg_generated_metrics['repetition_rate_trigrams']:.4f}\")\n",
    "        print(f\"Generated Unique Words Existing in Corpus (Avg): {avg_generated_metrics['existing_words_count']:.2f}\")\n",
    "        print(f\"Existence Rate (Generated Unique Words) (Avg): {avg_generated_metrics['existence_rate']:.2f}%\")\n",
    "        print(\"-----------------------------------------------------\")\n",
    "\n",
    "        print(\"\\n--- Letras Originais do Teste (Média) ---\")\n",
    "        print(f\"Total Words (Avg): {avg_actual_metrics['total_words']:.2f}\")\n",
    "        print(f\"Unique Words (Avg): {avg_actual_metrics['unique_words']:.2f}\")\n",
    "        print(f\"TTR (Distinct-1 Ratio) (Avg): {avg_actual_metrics['distinct_1_ratio']:.4f}\")\n",
    "        print(f\"Repetition Rate (1-Distinct-1) (Avg): {avg_actual_metrics['repetition_rate_words']:.4f}\")\n",
    "        print(f\"Distinct-2 Ratio (Bigrams) (Avg): {avg_actual_metrics['distinct_2_ratio']:.4f}\")\n",
    "        print(f\"Repetition Rate (1-Distinct-2) (Bigrams) (Avg): {avg_actual_metrics['repetition_rate_bigrams']:.4f}\")\n",
    "        print(f\"Distinct-3 Ratio (Trigrams) (Avg): {avg_actual_metrics['distinct_3_ratio']:.4f}\")\n",
    "        print(f\"Repetition Rate (1-Distinct-3) (Trigrams) (Avg): {avg_actual_metrics['repetition_rate_trigrams']:.4f}\")\n",
    "        print(f\"Actual Unique Words Existing in Corpus (Avg): {avg_actual_metrics['existing_words_count']:.2f}\")\n",
    "        print(f\"Existence Rate (Actual Unique Words) (Avg): {avg_actual_metrics['existence_rate']:.2f}%\")\n",
    "        print(\"-----------------------------------------------------\")\n",
    "    else:\n",
    "        print(\"No metrics generated for this strategy due to data issues.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e5aaae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- AVALIAÇÃO: Modelo com Dropout 'between_lstm' ---\n",
      "Model 'model_weights_arianagrande_strategy_between_lstm_best.pt' loaded from: models_by_artist_char_split\\arianagrande\\model_weights_arianagrande_strategy_between_lstm_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Loss/Acc: 100%|██████████| 352/352 [00:14<00:00, 23.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Avaliação de Geração de Músicas (Música a Música) para 'ArianaGrande' (Dropout: between_lstm) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating words: 100%|██████████| 3/3 [00:00<00:00, 13.74it/s]:00<?, ?it/s]\n",
      "Generating words: 674it [01:12,  9.27it/s]|▎         | 1/29 [00:00<00:06,  4.43it/s]\n",
      "Generating words: 100%|██████████| 775/775 [01:30<00:00,  8.61it/s]19:17, 42.86s/it]\n",
      "Generating words: 100%|██████████| 519/519 [00:54<00:00,  9.47it/s]27:54, 64.42s/it]\n",
      "Generating words: 100%|██████████| 510/510 [00:52<00:00,  9.80it/s]25:15, 60.64s/it]\n",
      "Generating words: 100%|██████████| 402/402 [00:36<00:00, 10.96it/s]23:00, 57.54s/it]\n",
      "Generating words: 100%|██████████| 372/372 [00:36<00:00, 10.30it/s]19:20, 50.45s/it]\n",
      "Generating words: 100%|██████████| 381/381 [00:45<00:00,  8.36it/s]16:46, 45.77s/it]\n",
      "Generating words: 100%|██████████| 14/14 [00:01<00:00,  8.69it/s]8<15:59, 45.71s/it]\n",
      "Generating words: 100%|██████████| 316/316 [00:36<00:00,  8.76it/s]10:38, 31.93s/it]\n",
      "Generating words: 100%|██████████| 526/526 [00:56<00:00,  9.33it/s]<10:31, 33.21s/it]\n",
      "Generating words: 14it [00:01,  9.41it/s]%|███▊      | 11/29 [08:02<12:05, 40.31s/it]\n",
      "Generating words: 100%|██████████| 337/337 [00:34<00:00,  9.84it/s]<08:04, 28.51s/it]\n",
      "Generating words: 100%|██████████| 89/89 [00:09<00:00,  9.68it/s]38<08:03, 30.25s/it]\n",
      "Generating words: 100%|██████████| 336/336 [00:33<00:00, 10.15it/s]<05:58, 23.89s/it]\n",
      "Generating words: 100%|██████████| 23/23 [00:02<00:00, 10.54it/s]20<06:13, 26.67s/it]\n",
      "Generating words: 100%|██████████| 494/494 [00:48<00:00, 10.11it/s]<04:10, 19.30s/it]\n",
      "Generating words: 100%|██████████| 443/443 [00:41<00:00, 10.65it/s]<05:38, 28.20s/it]\n",
      "Generating words: 100%|██████████| 45/45 [00:04<00:00, 11.07it/s]53<05:54, 32.23s/it]\n",
      "Generating words: 100%|██████████| 268/268 [00:24<00:00, 10.97it/s]<03:57, 23.77s/it]\n",
      "Generating words: 100%|██████████| 383/383 [00:39<00:00,  9.75it/s]<03:35, 23.97s/it]\n",
      "Generating words: 100%|██████████| 477/477 [00:44<00:00, 10.81it/s]<03:48, 28.57s/it]\n",
      "Generating words: 100%|██████████| 154/154 [00:14<00:00, 10.60it/s]<03:52, 33.25s/it]\n",
      "Generating words: 100%|██████████| 463/463 [00:44<00:00, 10.37it/s]<02:45, 27.64s/it]\n",
      "Generating words: 100%|██████████| 359/359 [00:37<00:00,  9.63it/s]<02:43, 32.75s/it]\n",
      "Generating words: 262it [00:17, 15.21it/s]                         <02:16, 34.12s/it]\n",
      "Generating words: 100%|██████████| 153/153 [00:08<00:00, 17.09it/s]<01:27, 29.05s/it]\n",
      "Generating words: 100%|██████████| 567/567 [00:31<00:00, 17.97it/s]<00:46, 23.03s/it]\n",
      "Generating words: 100%|██████████| 19/19 [00:00<00:00, 21.63it/s]19<00:25, 25.59s/it]\n",
      "Generating & Evaluating between_lstm: 100%|██████████| 29/29 [15:20<00:00, 31.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- MÉDIAS DAS MÉTRICAS DE GERAÇÃO (Dropout: between_lstm) ---\n",
      "\n",
      "--- Letras Geradas (Média) ---\n",
      "Total Words (Avg): 344.24\n",
      "Unique Words (Avg): 120.48\n",
      "TTR (Distinct-1 Ratio) (Avg): 0.4314\n",
      "Repetition Rate (1-Distinct-1) (Avg): 0.5686\n",
      "Distinct-2 Ratio (Bigrams) (Avg): 0.7454\n",
      "Repetition Rate (1-Distinct-2) (Bigrams) (Avg): 0.2546\n",
      "Distinct-3 Ratio (Trigrams) (Avg): 0.8379\n",
      "Repetition Rate (1-Distinct-3) (Trigrams) (Avg): 0.1621\n",
      "Generated Unique Words Existing in Corpus (Avg): 115.41\n",
      "Existence Rate (Generated Unique Words) (Avg): 0.96%\n",
      "-----------------------------------------------------\n",
      "\n",
      "--- Letras Originais do Teste (Média) ---\n",
      "Total Words (Avg): 342.93\n",
      "Unique Words (Avg): 91.79\n",
      "TTR (Distinct-1 Ratio) (Avg): 0.3644\n",
      "Repetition Rate (1-Distinct-1) (Avg): 0.6356\n",
      "Distinct-2 Ratio (Bigrams) (Avg): 0.5176\n",
      "Repetition Rate (1-Distinct-2) (Bigrams) (Avg): 0.4824\n",
      "Distinct-3 Ratio (Trigrams) (Avg): 0.5837\n",
      "Repetition Rate (1-Distinct-3) (Trigrams) (Avg): 0.4163\n",
      "Actual Unique Words Existing in Corpus (Avg): 91.79\n",
      "Existence Rate (Actual Unique Words) (Avg): 1.00%\n",
      "-----------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Executa a avaliação completa para um modelo pré-treinado com uma estratégia\n",
    "de dropout específica. Carrega os pesos do modelo, calcula a perda e a\n",
    "acurácia no conjunto de teste e, em seguida, itera sobre cada música de\n",
    "teste para gerar uma nova versão. Por fim, calcula e exibe as médias das\n",
    "métricas de qualidade de texto para as letras geradas e as originais,\n",
    "permitindo uma comparação direta.\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n--- AVALIAÇÃO: Modelo com Dropout 'between_lstm' ---\")\n",
    "\n",
    "CURRENT_DROPOUT_STRATEGY = \"between_lstm\" \n",
    "MODEL_SAVE_FILENAME = f\"model_weights_{CLEAN_TARGET_ARTIST_NAME}_strategy_{CURRENT_DROPOUT_STRATEGY}_best.pt\"\n",
    "model_save_filepath = os.path.join(MODEL_DIR_ARTIST, MODEL_SAVE_FILENAME)\n",
    "\n",
    "if not os.path.exists(model_save_filepath):\n",
    "    print(f\"Error: Trained model '{model_save_filepath}' for strategy '{CURRENT_DROPOUT_STRATEGY}' not found. Please train this model first.\")\n",
    "    exit() \n",
    "\n",
    "model = CharLSTM(\n",
    "    vocab_size=total_chars,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    n_layers=N_LAYERS,\n",
    "    dropout_rate=DROPOUT_RATE,\n",
    "    dropout_strategy=CURRENT_DROPOUT_STRATEGY \n",
    ").to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(model_save_filepath, map_location=device))\n",
    "print(f\"Model '{MODEL_SAVE_FILENAME}' loaded from: {model_save_filepath}\")\n",
    "\n",
    "# --- Calcular Loss e Acurácia de Caractere (no conjunto de teste tokenizado) ---\n",
    "test_loss, test_accuracy = evaluate_model_loss_acc(model, test_loader, criterion, device)\n",
    "perplexity = np.exp(test_loss) if not np.isnan(test_loss) else float('nan')\n",
    "\n",
    "print(f\"\\n--- Avaliação de Geração de Músicas (Música a Música) para '{TARGET_ARTIST}' (Dropout: {CURRENT_DROPOUT_STRATEGY}) ---\")\n",
    "\n",
    "all_generated_lyrics_metrics = []\n",
    "all_actual_lyrics_metrics = []\n",
    "if not TEST_LYRICS_ARTIST_FINAL_SONGS:\n",
    "    print(\"WARNING: No artist test songs available for generation. Skipping song-by-song evaluation.\")\n",
    "else:\n",
    "    for i, original_lyric_text in enumerate(tqdm(TEST_LYRICS_ARTIST_FINAL_SONGS, desc=f\"Generating & Evaluating {CURRENT_DROPOUT_STRATEGY}\")):\n",
    "        original_lyric_words = nltk.word_tokenize(original_lyric_text)\n",
    "        target_word_count = len(original_lyric_words)\n",
    "\n",
    "        if target_word_count < 20: \n",
    "            target_word_count = 20\n",
    "        \n",
    "        if len(original_lyric_text) < SEQUENCE_LENGTH:\n",
    "            seed_text = ' ' * (SEQUENCE_LENGTH - len(original_lyric_text)) + original_lyric_text\n",
    "        else:\n",
    "            seed_text = original_lyric_text[:SEQUENCE_LENGTH]\n",
    "\n",
    "        # Gerar a Música\n",
    "        generated_lyric_text = generate_text_by_word_count(model, tokenizer, seed_text, \n",
    "                                                           target_word_count, \n",
    "                                                           temperature=0.8, \n",
    "                                                           sequence_length=SEQUENCE_LENGTH, \n",
    "                                                           device=device)\n",
    "        \n",
    "        # Calcular Métricas para a Letra Gerada\n",
    "        metrics_generated = calculate_text_quality_metrics_updated(generated_lyric_text, existing_words_in_corpus)\n",
    "        all_generated_lyrics_metrics.append(metrics_generated)\n",
    "\n",
    "        # Calcular Métricas para a Letra Original (para comparação)\n",
    "        metrics_actual = calculate_text_quality_metrics_updated(original_lyric_text, existing_words_in_corpus)\n",
    "        all_actual_lyrics_metrics.append(metrics_actual)\n",
    "\n",
    "    # Calcular a Média das Métricas\n",
    "    if all_generated_lyrics_metrics:\n",
    "        avg_generated_metrics = {k: np.mean([d[k] for d in all_generated_lyrics_metrics if d[k] is not None]) for k in all_generated_lyrics_metrics[0]}\n",
    "        avg_actual_metrics = {k: np.mean([d[k] for d in all_actual_lyrics_metrics if d[k] is not None]) for k in all_actual_lyrics_metrics[0]}\n",
    "        \n",
    "        print(f\"\\n--- MÉDIAS DAS MÉTRICAS DE GERAÇÃO (Dropout: {CURRENT_DROPOUT_STRATEGY}) ---\")\n",
    "        print(\"\\n--- Letras Geradas (Média) ---\")\n",
    "        print(f\"Total Words (Avg): {avg_generated_metrics['total_words']:.2f}\")\n",
    "        print(f\"Unique Words (Avg): {avg_generated_metrics['unique_words']:.2f}\")\n",
    "        print(f\"TTR (Distinct-1 Ratio) (Avg): {avg_generated_metrics['distinct_1_ratio']:.4f}\")\n",
    "        print(f\"Repetition Rate (1-Distinct-1) (Avg): {avg_generated_metrics['repetition_rate_words']:.4f}\")\n",
    "        print(f\"Distinct-2 Ratio (Bigrams) (Avg): {avg_generated_metrics['distinct_2_ratio']:.4f}\")\n",
    "        print(f\"Repetition Rate (1-Distinct-2) (Bigrams) (Avg): {avg_generated_metrics['repetition_rate_bigrams']:.4f}\")\n",
    "        print(f\"Distinct-3 Ratio (Trigrams) (Avg): {avg_generated_metrics['distinct_3_ratio']:.4f}\")\n",
    "        print(f\"Repetition Rate (1-Distinct-3) (Trigrams) (Avg): {avg_generated_metrics['repetition_rate_trigrams']:.4f}\")\n",
    "        print(f\"Generated Unique Words Existing in Corpus (Avg): {avg_generated_metrics['existing_words_count']:.2f}\")\n",
    "        print(f\"Existence Rate (Generated Unique Words) (Avg): {avg_generated_metrics['existence_rate']:.2f}%\")\n",
    "        print(\"-----------------------------------------------------\")\n",
    "\n",
    "        print(\"\\n--- Letras Originais do Teste (Média) ---\")\n",
    "        print(f\"Total Words (Avg): {avg_actual_metrics['total_words']:.2f}\")\n",
    "        print(f\"Unique Words (Avg): {avg_actual_metrics['unique_words']:.2f}\")\n",
    "        print(f\"TTR (Distinct-1 Ratio) (Avg): {avg_actual_metrics['distinct_1_ratio']:.4f}\")\n",
    "        print(f\"Repetition Rate (1-Distinct-1) (Avg): {avg_actual_metrics['repetition_rate_words']:.4f}\")\n",
    "        print(f\"Distinct-2 Ratio (Bigrams) (Avg): {avg_actual_metrics['distinct_2_ratio']:.4f}\")\n",
    "        print(f\"Repetition Rate (1-Distinct-2) (Bigrams) (Avg): {avg_actual_metrics['repetition_rate_bigrams']:.4f}\")\n",
    "        print(f\"Distinct-3 Ratio (Trigrams) (Avg): {avg_actual_metrics['distinct_3_ratio']:.4f}\")\n",
    "        print(f\"Repetition Rate (1-Distinct-3) (Trigrams) (Avg): {avg_actual_metrics['repetition_rate_trigrams']:.4f}\")\n",
    "        print(f\"Actual Unique Words Existing in Corpus (Avg): {avg_actual_metrics['existing_words_count']:.2f}\")\n",
    "        print(f\"Existence Rate (Actual Unique Words) (Avg): {avg_actual_metrics['existence_rate']:.2f}%\")\n",
    "        print(\"-----------------------------------------------------\")\n",
    "    else:\n",
    "        print(\"No metrics generated for this strategy due to data issues.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85a8381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- AVALIAÇÃO: Modelo com Dropout 'before_fc' ---\n",
      "Model 'model_weights_arianagrande_strategy_before_fc_best.pt' loaded from: models_by_artist_char_split\\arianagrande\\model_weights_arianagrande_strategy_before_fc_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Loss/Acc: 100%|██████████| 352/352 [00:12<00:00, 27.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Avaliação de Geração de Músicas (Música a Música) para 'ArianaGrande' (Dropout: before_fc) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating words: 100%|██████████| 3/3 [00:00<00:00, 12.46it/s]<?, ?it/s]\n",
      "Generating words: 100%|██████████| 673/673 [00:48<00:00, 13.75it/s]06,  4.10it/s]\n",
      "Generating words: 100%|██████████| 775/775 [01:06<00:00, 11.57it/s]00, 28.92s/it]\n",
      "Generating words: 100%|██████████| 519/519 [00:36<00:00, 14.38it/s]04, 46.31s/it]\n",
      "Generating words: 100%|██████████| 510/510 [00:38<00:00, 13.11it/s]37, 42.29s/it]\n",
      "Generating words: 100%|██████████| 402/402 [00:32<00:00, 12.35it/s]25, 41.07s/it]\n",
      "Generating words: 100%|██████████| 372/372 [00:31<00:00, 11.77it/s]38, 38.18s/it]\n",
      "Generating words: 100%|██████████| 381/381 [00:31<00:00, 12.08it/s]12, 36.04s/it]\n",
      "Generating words: 15it [00:01,  8.48it/s]█▊       | 8/29 [04:47<12:06, 34.61s/it]\n",
      "Generating words: 100%|██████████| 316/316 [00:21<00:00, 14.56it/s]06, 24.34s/it]\n",
      "Generating words: 100%|██████████| 526/526 [00:33<00:00, 15.87it/s]:27, 23.53s/it]\n",
      "Generating words: 100%|██████████| 13/13 [00:00<00:00, 16.88it/s]07:56, 26.48s/it]\n",
      "Generating words: 100%|██████████| 337/337 [00:23<00:00, 14.19it/s]:17, 18.66s/it]\n",
      "Generating words: 100%|██████████| 89/89 [00:07<00:00, 12.30it/s]05:23, 20.20s/it]\n",
      "Generating words: 100%|██████████| 336/336 [00:33<00:00,  9.98it/s]:04, 16.29s/it]\n",
      "Generating words: 100%|██████████| 23/23 [00:02<00:00, 10.10it/s]05:01, 21.53s/it]\n",
      "Generating words: 100%|██████████| 494/494 [00:45<00:00, 10.91it/s]:24, 15.74s/it]\n",
      "Generating words: 100%|██████████| 443/443 [00:39<00:00, 11.11it/s]:55, 24.63s/it]\n",
      "Generating words: 46it [00:04, 10.88it/s]█████▏   | 18/29 [08:16<05:21, 29.21s/it]\n",
      "Generating words: 100%|██████████| 268/268 [00:21<00:00, 12.46it/s]:37, 21.71s/it]\n",
      "Generating words: 100%|██████████| 383/383 [00:32<00:00, 11.63it/s]:14, 21.65s/it]\n",
      "Generating words: 100%|██████████| 477/477 [00:42<00:00, 11.29it/s]:20, 25.04s/it]\n",
      "Generating words: 100%|██████████| 154/154 [00:15<00:00,  9.75it/s]:31, 30.22s/it]\n",
      "Generating words: 100%|██████████| 463/463 [00:42<00:00, 10.79it/s]:35, 25.89s/it]\n",
      "Generating words: 100%|██████████| 359/359 [00:32<00:00, 10.93it/s]:35, 31.00s/it]\n",
      "Generating words: 100%|██████████| 261/261 [00:24<00:00, 10.72it/s]:06, 31.56s/it]\n",
      "Generating words: 100%|██████████| 153/153 [00:12<00:00, 12.13it/s]:28, 29.40s/it]\n",
      "Generating words: 100%|██████████| 567/567 [00:54<00:00, 10.44it/s]:48, 24.37s/it]\n",
      "Generating words: 100%|██████████| 19/19 [00:02<00:00,  7.87it/s]00:33, 33.35s/it]\n",
      "Generating & Evaluating before_fc: 100%|██████████| 29/29 [13:02<00:00, 27.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- MÉDIAS DAS MÉTRICAS DE GERAÇÃO (Dropout: before_fc) ---\n",
      "\n",
      "--- Letras Geradas (Média) ---\n",
      "Total Words (Avg): 344.21\n",
      "Unique Words (Avg): 124.00\n",
      "TTR (Distinct-1 Ratio) (Avg): 0.4449\n",
      "Repetition Rate (1-Distinct-1) (Avg): 0.5551\n",
      "Distinct-2 Ratio (Bigrams) (Avg): 0.7552\n",
      "Repetition Rate (1-Distinct-2) (Bigrams) (Avg): 0.2448\n",
      "Distinct-3 Ratio (Trigrams) (Avg): 0.8441\n",
      "Repetition Rate (1-Distinct-3) (Trigrams) (Avg): 0.1559\n",
      "Generated Unique Words Existing in Corpus (Avg): 115.00\n",
      "Existence Rate (Generated Unique Words) (Avg): 0.93%\n",
      "-----------------------------------------------------\n",
      "\n",
      "--- Letras Originais do Teste (Média) ---\n",
      "Total Words (Avg): 342.93\n",
      "Unique Words (Avg): 91.79\n",
      "TTR (Distinct-1 Ratio) (Avg): 0.3644\n",
      "Repetition Rate (1-Distinct-1) (Avg): 0.6356\n",
      "Distinct-2 Ratio (Bigrams) (Avg): 0.5176\n",
      "Repetition Rate (1-Distinct-2) (Bigrams) (Avg): 0.4824\n",
      "Distinct-3 Ratio (Trigrams) (Avg): 0.5837\n",
      "Repetition Rate (1-Distinct-3) (Trigrams) (Avg): 0.4163\n",
      "Actual Unique Words Existing in Corpus (Avg): 91.79\n",
      "Existence Rate (Actual Unique Words) (Avg): 1.00%\n",
      "-----------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Executa a avaliação completa para um modelo pré-treinado com uma estratégia\n",
    "de dropout específica. Carrega os pesos do modelo, calcula a perda e a\n",
    "acurácia no conjunto de teste e, em seguida, itera sobre cada música de\n",
    "teste para gerar uma nova versão. Por fim, calcula e exibe as médias das\n",
    "métricas de qualidade de texto para as letras geradas e as originais,\n",
    "permitindo uma comparação direta.\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n--- AVALIAÇÃO: Modelo com Dropout 'before_fc' ---\")\n",
    "\n",
    "CURRENT_DROPOUT_STRATEGY = \"before_fc\" \n",
    "MODEL_SAVE_FILENAME = f\"model_weights_{CLEAN_TARGET_ARTIST_NAME}_strategy_{CURRENT_DROPOUT_STRATEGY}_best.pt\"\n",
    "model_save_filepath = os.path.join(MODEL_DIR_ARTIST, MODEL_SAVE_FILENAME)\n",
    "\n",
    "if not os.path.exists(model_save_filepath):\n",
    "    print(f\"Error: Trained model '{model_save_filepath}' for strategy '{CURRENT_DROPOUT_STRATEGY}' not found. Please train this model first.\")\n",
    "    exit() \n",
    "\n",
    "model = CharLSTM(\n",
    "    vocab_size=total_chars,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    n_layers=N_LAYERS,\n",
    "    dropout_rate=DROPOUT_RATE,\n",
    "    dropout_strategy=CURRENT_DROPOUT_STRATEGY \n",
    ").to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(model_save_filepath, map_location=device))\n",
    "print(f\"Model '{MODEL_SAVE_FILENAME}' loaded from: {model_save_filepath}\")\n",
    "\n",
    "# --- Calcular Loss e Acurácia de Caractere (no conjunto de teste tokenizado) ---\n",
    "test_loss, test_accuracy = evaluate_model_loss_acc(model, test_loader, criterion, device)\n",
    "perplexity = np.exp(test_loss) if not np.isnan(test_loss) else float('nan')\n",
    "\n",
    "print(f\"\\n--- Avaliação de Geração de Músicas (Música a Música) para '{TARGET_ARTIST}' (Dropout: {CURRENT_DROPOUT_STRATEGY}) ---\")\n",
    "\n",
    "all_generated_lyrics_metrics = []\n",
    "all_actual_lyrics_metrics = []\n",
    "if not TEST_LYRICS_ARTIST_FINAL_SONGS:\n",
    "    print(\"WARNING: No artist test songs available for generation. Skipping song-by-song evaluation.\")\n",
    "else:\n",
    "    for i, original_lyric_text in enumerate(tqdm(TEST_LYRICS_ARTIST_FINAL_SONGS, desc=f\"Generating & Evaluating {CURRENT_DROPOUT_STRATEGY}\")):\n",
    "        original_lyric_words = nltk.word_tokenize(original_lyric_text)\n",
    "        target_word_count = len(original_lyric_words)\n",
    "\n",
    "        if target_word_count < 20: \n",
    "            target_word_count = 20\n",
    "        \n",
    "        if len(original_lyric_text) < SEQUENCE_LENGTH:\n",
    "            seed_text = ' ' * (SEQUENCE_LENGTH - len(original_lyric_text)) + original_lyric_text\n",
    "        else:\n",
    "            seed_text = original_lyric_text[:SEQUENCE_LENGTH]\n",
    "\n",
    "        # Gerar a Música\n",
    "        generated_lyric_text = generate_text_by_word_count(model, tokenizer, seed_text, \n",
    "                                                           target_word_count, \n",
    "                                                           temperature=0.8, \n",
    "                                                           sequence_length=SEQUENCE_LENGTH, \n",
    "                                                           device=device)\n",
    "        \n",
    "        # Calcular Métricas para a Letra Gerada\n",
    "        metrics_generated = calculate_text_quality_metrics_updated(generated_lyric_text, existing_words_in_corpus)\n",
    "        all_generated_lyrics_metrics.append(metrics_generated)\n",
    "\n",
    "        # Calcular Métricas para a Letra Original (para comparação)\n",
    "        metrics_actual = calculate_text_quality_metrics_updated(original_lyric_text, existing_words_in_corpus)\n",
    "        all_actual_lyrics_metrics.append(metrics_actual)\n",
    "\n",
    "    # Calcular a Média das Métricas\n",
    "    if all_generated_lyrics_metrics:\n",
    "        avg_generated_metrics = {k: np.mean([d[k] for d in all_generated_lyrics_metrics if d[k] is not None]) for k in all_generated_lyrics_metrics[0]}\n",
    "        avg_actual_metrics = {k: np.mean([d[k] for d in all_actual_lyrics_metrics if d[k] is not None]) for k in all_actual_lyrics_metrics[0]}\n",
    "        \n",
    "        print(f\"\\n--- MÉDIAS DAS MÉTRICAS DE GERAÇÃO (Dropout: {CURRENT_DROPOUT_STRATEGY}) ---\")\n",
    "        print(\"\\n--- Letras Geradas (Média) ---\")\n",
    "        print(f\"Total Words (Avg): {avg_generated_metrics['total_words']:.2f}\")\n",
    "        print(f\"Unique Words (Avg): {avg_generated_metrics['unique_words']:.2f}\")\n",
    "        print(f\"TTR (Distinct-1 Ratio) (Avg): {avg_generated_metrics['distinct_1_ratio']:.4f}\")\n",
    "        print(f\"Repetition Rate (1-Distinct-1) (Avg): {avg_generated_metrics['repetition_rate_words']:.4f}\")\n",
    "        print(f\"Distinct-2 Ratio (Bigrams) (Avg): {avg_generated_metrics['distinct_2_ratio']:.4f}\")\n",
    "        print(f\"Repetition Rate (1-Distinct-2) (Bigrams) (Avg): {avg_generated_metrics['repetition_rate_bigrams']:.4f}\")\n",
    "        print(f\"Distinct-3 Ratio (Trigrams) (Avg): {avg_generated_metrics['distinct_3_ratio']:.4f}\")\n",
    "        print(f\"Repetition Rate (1-Distinct-3) (Trigrams) (Avg): {avg_generated_metrics['repetition_rate_trigrams']:.4f}\")\n",
    "        print(f\"Generated Unique Words Existing in Corpus (Avg): {avg_generated_metrics['existing_words_count']:.2f}\")\n",
    "        print(f\"Existence Rate (Generated Unique Words) (Avg): {avg_generated_metrics['existence_rate']:.2f}%\")\n",
    "        print(\"-----------------------------------------------------\")\n",
    "\n",
    "        print(\"\\n--- Letras Originais do Teste (Média) ---\")\n",
    "        print(f\"Total Words (Avg): {avg_actual_metrics['total_words']:.2f}\")\n",
    "        print(f\"Unique Words (Avg): {avg_actual_metrics['unique_words']:.2f}\")\n",
    "        print(f\"TTR (Distinct-1 Ratio) (Avg): {avg_actual_metrics['distinct_1_ratio']:.4f}\")\n",
    "        print(f\"Repetition Rate (1-Distinct-1) (Avg): {avg_actual_metrics['repetition_rate_words']:.4f}\")\n",
    "        print(f\"Distinct-2 Ratio (Bigrams) (Avg): {avg_actual_metrics['distinct_2_ratio']:.4f}\")\n",
    "        print(f\"Repetition Rate (1-Distinct-2) (Bigrams) (Avg): {avg_actual_metrics['repetition_rate_bigrams']:.4f}\")\n",
    "        print(f\"Distinct-3 Ratio (Trigrams) (Avg): {avg_actual_metrics['distinct_3_ratio']:.4f}\")\n",
    "        print(f\"Repetition Rate (1-Distinct-3) (Trigrams) (Avg): {avg_actual_metrics['repetition_rate_trigrams']:.4f}\")\n",
    "        print(f\"Actual Unique Words Existing in Corpus (Avg): {avg_actual_metrics['existing_words_count']:.2f}\")\n",
    "        print(f\"Existence Rate (Actual Unique Words) (Avg): {avg_actual_metrics['existence_rate']:.2f}%\")\n",
    "        print(\"-----------------------------------------------------\")\n",
    "    else:\n",
    "        print(\"No metrics generated for this strategy due to data issues.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca66026",
   "metadata": {},
   "source": [
    "### Sem Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0055533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- AVALIAÇÃO: Modelo com Dropout 'none' ---\n",
      "Model 'model_weights_arianagrande_strategy_none_best.pt' loaded from: models_by_artist_char_split\\arianagrande\\model_weights_arianagrande_strategy_none_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Loss/Acc: 100%|██████████| 357/357 [00:14<00:00, 24.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Resultados de Avaliação no Conjunto de TESTE (Caracter): 'ArianaGrande' (Dropout: none) ---\n",
      "Perplexity: 2.1358\n",
      "-----------------------------------------------------\n",
      "\n",
      "Starting word-level evaluation for 9916 test prompts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Next Word & POS Tag: 100%|██████████| 9916/9916 [12:41<00:00, 13.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results: Grammatical Cohesion (POS) & Next Word Accuracy (Dropout: none) ---\n",
      "Total prompts evaluated: 9916\n",
      "Correct POS Tag Predictions: 5105\n",
      "Overall Next POS Tag Accuracy: 51.48%\n",
      "Correct Next Word Predictions: 3389\n",
      "Overall Next Word Prediction Accuracy: 34.18%\n",
      "-----------------------------------------------------\n",
      "\n",
      "--- Metrics for GENERATED WORDS (from next-word prediction task) ---\n",
      "Total Generated Words: 10670\n",
      "Unique Generated Words: 510\n",
      "TTR (Generated Words): 0.0478\n",
      "Repetition Rate (Generated Words): 0.9522\n",
      "Generated Unique Words Existing in Corpus: 466\n",
      "Existence Rate (Generated Unique Words): 0.91%\n",
      "-----------------------------------------------------\n",
      "\n",
      "--- Metrics for ACTUAL TEST WORDS (from artist's test set) ---\n",
      "Total Actual Test Words: 9916\n",
      "Unique Actual Test Words: 998\n",
      "TTR (Actual Test Words): 0.1006\n",
      "Repetition Rate (Actual Test Words): 0.8994\n",
      "Actual Unique Words Existing in Corpus: 998\n",
      "Existence Rate (Actual Unique Words): 1.00%\n",
      "-----------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Executa uma avaliação focada na predição da próxima palavra para um modelo\n",
    "específico. Carrega os pesos do modelo, calcula a perplexidade no conjunto\n",
    "de teste e, em seguida, avalia a precisão da próxima palavra e da próxima\n",
    "etiqueta POS. Também analisa e compara as métricas de qualidade (TTR, taxa\n",
    "de repetição) do conjunto de palavras geradas versus o conjunto de palavras\n",
    "reais do teste.\n",
    "\"\"\"\n",
    "print(\"\\nAvaliação do Modelo com Dropout 'none': Foco em Predição da Próxima Palavra\")\n",
    "CURRENT_DROPOUT_STRATEGY = \"none\"\n",
    "MODEL_SAVE_FILENAME = f\"model_weights_{CLEAN_TARGET_ARTIST_NAME}_strategy_{CURRENT_DROPOUT_STRATEGY}_best.pt\"\n",
    "model_save_filepath = os.path.join(MODEL_DIR_ARTIST, MODEL_SAVE_FILENAME)\n",
    "\n",
    "if not os.path.exists(model_save_filepath):\n",
    "    print(f\"Erro: Modelo treinado '{model_save_filepath}' para a estratégia '{CURRENT_DROPOUT_STRATEGY}' não encontrado.\")\n",
    "else:\n",
    "    model = CharLSTM(\n",
    "        vocab_size=total_chars,\n",
    "        embedding_dim=EMBEDDING_DIM,\n",
    "        hidden_dim=HIDDEN_DIM,\n",
    "        n_layers=N_LAYERS,\n",
    "        dropout_rate=DROPOUT_RATE,\n",
    "        dropout_strategy=CURRENT_DROPOUT_STRATEGY\n",
    "    ).to(device)\n",
    "\n",
    "    model.load_state_dict(torch.load(model_save_filepath, map_location=device))\n",
    "    print(f\"Modelo '{MODEL_SAVE_FILENAME}' carregado de: {model_save_filepath}\")\n",
    "\n",
    "    test_loss, test_accuracy = evaluate_model_loss_acc(model, test_loader, criterion, device)\n",
    "    perplexity = np.exp(test_loss) if not np.isnan(test_loss) else float('nan')\n",
    "    print(f\"\\nPerplexidade no conjunto de teste: {perplexity:.4f}\")\n",
    "\n",
    "    correct_pos_predictions = 0\n",
    "    correct_word_predictions = 0\n",
    "    total_predictions_attempted = 0\n",
    "    pos_confusion_matrix = {}\n",
    "    generated_words_list = []\n",
    "\n",
    "    if not prompts_for_eval or not true_next_words or not nlp:\n",
    "        print(\"\\nAviso: Dados insuficientes para a avaliação de nível de palavra. Pulando.\")\n",
    "    else:\n",
    "        print(f\"\\nIniciando avaliação de nível de palavra para {len(prompts_for_eval)} prompts...\")\n",
    "        for i in tqdm(range(len(prompts_for_eval)), desc=\"Avaliando Próxima Palavra & POS Tag\"):\n",
    "            prompt = prompts_for_eval[i]\n",
    "            true_word = true_next_words[i]\n",
    "            true_pos = true_next_pos_tags[i]\n",
    "\n",
    "            generated_word = generate_next_word_from_prompt_eval(model, tokenizer, prompt, SEQUENCE_LENGTH, device)\n",
    "            generated_words_list.append(generated_word)\n",
    "\n",
    "            generated_pos = \"NONE\"\n",
    "            if generated_word:\n",
    "                doc_generated = nlp(generated_word)\n",
    "                generated_pos = doc_generated[0].pos_ if doc_generated and doc_generated[0] else \"UNKNOWN\"\n",
    "            \n",
    "            pos_confusion_matrix.setdefault(true_pos, {})\n",
    "            pos_confusion_matrix[true_pos].setdefault(generated_pos, 0)\n",
    "            pos_confusion_matrix[true_pos][generated_pos] += 1\n",
    "\n",
    "            if generated_pos == true_pos:\n",
    "                correct_pos_predictions += 1\n",
    "            \n",
    "            cleaned_true_word = re.sub(r'[^a-z0-9]', '', true_word).lower()\n",
    "            cleaned_generated_word = re.sub(r'[^a-z0-9]', '', generated_word).lower()\n",
    "\n",
    "            if cleaned_generated_word == cleaned_true_word and cleaned_true_word != \"\":\n",
    "                correct_word_predictions += 1\n",
    "            total_predictions_attempted += 1\n",
    "\n",
    "        overall_pos_accuracy = (correct_pos_predictions / total_predictions_attempted) * 100 if total_predictions_attempted > 0 else 0.0\n",
    "        overall_word_accuracy = (correct_word_predictions / total_predictions_attempted) * 100 if total_predictions_attempted > 0 else 0.0\n",
    "\n",
    "        print(f\"\\nResultados de Coesão Gramatical e Predição da Próxima Palavra (Dropout: {CURRENT_DROPOUT_STRATEGY})\")\n",
    "        print(f\"Total de prompts avaliados: {total_predictions_attempted}\")\n",
    "        print(f\"Acurácia da Próxima Etiqueta POS: {overall_pos_accuracy:.2f}%\")\n",
    "        print(f\"Acurácia da Próxima Palavra: {overall_word_accuracy:.2f}%\")\n",
    "\n",
    "        print(\"\\nMétricas para o conjunto de PALAVRAS GERADAS (na tarefa de predição)\")\n",
    "        generated_word_metrics = calculate_text_quality_metrics(\" \".join(generated_words_list), existing_words_in_corpus)\n",
    "        for key, value in generated_word_metrics.items():\n",
    "            print(f\"{key.replace('_', ' ').title()}: {value:.4f}\")\n",
    "\n",
    "        print(\"\\nMétricas para o conjunto de PALAVRAS REAIS (do conjunto de teste)\")\n",
    "        actual_test_word_metrics = calculate_text_quality_metrics(\" \".join(true_next_words), existing_words_in_corpus)\n",
    "        for key, value in actual_test_word_metrics.items():\n",
    "            print(f\"{key.replace('_', ' ').title()}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d9f5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- AVALIAÇÃO: Modelo Sem Dropout (Estratégia 'none') ---\n",
      "Modelo 'model_weights_arianagrande_strategy_none_best.pt' carregado de: models_by_artist_char_split\\arianagrande\\model_weights_arianagrande_strategy_none_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avaliando: 100%|██████████| 353/353 [00:13<00:00, 27.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Resultados da Avaliação no Conjunto de TESTE para 'ArianaGrande' (Dropout: none) ---\n",
      "Perda de Teste (Test Loss): 0.9172\n",
      "Acurácia de Teste (Test Accuracy): 0.7288\n",
      "-----------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- AVALIAÇÃO: Modelo Sem Dropout (Estratégia 'none') ---\")\n",
    "\n",
    "CURRENT_DROPOUT_STRATEGY = \"none\" \n",
    "MODEL_SAVE_FILENAME = f\"model_weights_{CLEAN_TARGET_ARTIST_NAME}_strategy_{CURRENT_DROPOUT_STRATEGY}_best.pt\"\n",
    "model_save_filepath = os.path.join(MODEL_DIR_ARTIST, MODEL_SAVE_FILENAME)\n",
    "\n",
    "if not os.path.exists(model_save_filepath):\n",
    "    print(f\"Erro: Modelo treinado '{model_save_filepath}' para estratégia '{CURRENT_DROPOUT_STRATEGY}' não encontrado. Por favor, treine este modelo primeiro.\")\n",
    "    exit() \n",
    "\n",
    "model = CharLSTM(\n",
    "    vocab_size=total_chars,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    n_layers=N_LAYERS,\n",
    "    dropout_rate=DROPOUT_RATE,\n",
    "    dropout_strategy=CURRENT_DROPOUT_STRATEGY \n",
    ").to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(model_save_filepath, map_location=device))\n",
    "print(f\"Modelo '{MODEL_SAVE_FILENAME}' carregado de: {model_save_filepath}\")\n",
    "\n",
    "test_loss, test_accuracy = evaluate_model_loss_acc(model, test_loader, criterion, device)\n",
    "\n",
    "print(f\"\\n--- Resultados da Avaliação no Conjunto de TESTE para '{TARGET_ARTIST}' (Dropout: {CURRENT_DROPOUT_STRATEGY}) ---\")\n",
    "print(f\"Perda de Teste (Test Loss): {test_loss:.4f}\")\n",
    "print(f\"Acurácia de Teste (Test Accuracy): {test_accuracy:.4f}\")\n",
    "print(\"-----------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24decab9",
   "metadata": {},
   "source": [
    "### between_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304cbdc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo 'model_weights_arianagrande_strategy_between_lstm_best.pt' carregado de: models_by_artist_char_split\\arianagrande\\model_weights_arianagrande_strategy_between_lstm_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avaliando: 100%|██████████| 332/332 [00:13<00:00, 25.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Resultados da Avaliação no Conjunto de TESTE para 'ArianaGrande' (Dropout: between_lstm) ---\n",
      "Perda de Teste (Test Loss): 1.0660\n",
      "Acurácia de Teste (Test Accuracy): 0.6917\n",
      "-----------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "CURRENT_DROPOUT_STRATEGY = \"between_lstm\" \n",
    "MODEL_SAVE_FILENAME = f\"model_weights_{CLEAN_TARGET_ARTIST_NAME}_strategy_{CURRENT_DROPOUT_STRATEGY}_best.pt\"\n",
    "model_save_filepath = os.path.join(MODEL_DIR_ARTIST, MODEL_SAVE_FILENAME)\n",
    "\n",
    "if not os.path.exists(model_save_filepath):\n",
    "    print(f\"Erro: Modelo treinado '{model_save_filepath}' para estratégia '{CURRENT_DROPOUT_STRATEGY}' não encontrado. Por favor, treine este modelo primeiro.\")\n",
    "    exit()\n",
    "\n",
    "model = CharLSTM(\n",
    "    vocab_size=total_chars,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    n_layers=N_LAYERS,\n",
    "    dropout_rate=DROPOUT_RATE,\n",
    "    dropout_strategy=CURRENT_DROPOUT_STRATEGY \n",
    ").to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(model_save_filepath, map_location=device))\n",
    "print(f\"Modelo '{MODEL_SAVE_FILENAME}' carregado de: {model_save_filepath}\")\n",
    "\n",
    "test_loss, test_accuracy = evaluate_model_loss_acc(model, test_loader, criterion, device)\n",
    "\n",
    "print(f\"\\n--- Resultados da Avaliação no Conjunto de TESTE para '{TARGET_ARTIST}' (Dropout: {CURRENT_DROPOUT_STRATEGY}) ---\")\n",
    "print(f\"Perda de Teste (Test Loss): {test_loss:.4f}\")\n",
    "print(f\"Acurácia de Teste (Test Accuracy): {test_accuracy:.4f}\")\n",
    "print(\"-----------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90eea472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- AVALIAÇÃO: Modelo com Dropout 'none' ---\n",
      "Model 'model_weights_arianagrande_strategy_between_lstm_best.pt' loaded from: models_by_artist_char_split\\arianagrande\\model_weights_arianagrande_strategy_between_lstm_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Loss/Acc: 100%|██████████| 352/352 [00:14<00:00, 25.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Resultados de Avaliação no Conjunto de TESTE (Caracter): 'ArianaGrande' (Dropout: between_lstm) ---\n",
      "Perplexity: 2.1687\n",
      "-----------------------------------------------------\n",
      "\n",
      "Starting word-level evaluation for 9916 test prompts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Next Word & POS Tag: 100%|██████████| 9916/9916 [09:30<00:00, 17.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results: Grammatical Cohesion (POS) & Next Word Accuracy (Dropout: between_lstm) ---\n",
      "Total prompts evaluated: 9916\n",
      "Correct POS Tag Predictions: 4939\n",
      "Overall Next POS Tag Accuracy: 49.81%\n",
      "Correct Next Word Predictions: 2945\n",
      "Overall Next Word Prediction Accuracy: 29.70%\n",
      "-----------------------------------------------------\n",
      "\n",
      "--- Metrics for GENERATED WORDS (from next-word prediction task) ---\n",
      "Total Generated Words: 10765\n",
      "Unique Generated Words: 372\n",
      "TTR (Generated Words): 0.0346\n",
      "Repetition Rate (Generated Words): 0.9654\n",
      "Generated Unique Words Existing in Corpus: 358\n",
      "Existence Rate (Generated Unique Words): 0.96%\n",
      "-----------------------------------------------------\n",
      "\n",
      "--- Metrics for ACTUAL TEST WORDS (from artist's test set) ---\n",
      "Total Actual Test Words: 9916\n",
      "Unique Actual Test Words: 998\n",
      "TTR (Actual Test Words): 0.1006\n",
      "Repetition Rate (Actual Test Words): 0.8994\n",
      "Actual Unique Words Existing in Corpus: 998\n",
      "Existence Rate (Actual Unique Words): 1.00%\n",
      "-----------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Executa uma avaliação focada na predição da próxima palavra para um modelo\n",
    "específico. Carrega os pesos do modelo, calcula a perplexidade no conjunto\n",
    "de teste e, em seguida, avalia a precisão da próxima palavra e da próxima\n",
    "etiqueta POS. Também analisa e compara as métricas de qualidade (TTR, taxa\n",
    "de repetição) do conjunto de palavras geradas versus o conjunto de palavras\n",
    "reais do teste.\n",
    "\"\"\"\n",
    "print(\"\\nAvaliação do Modelo com Dropout 'between_lstm': Foco em Predição da Próxima Palavra\")\n",
    "CURRENT_DROPOUT_STRATEGY = \"between_lstm\"\n",
    "MODEL_SAVE_FILENAME = f\"model_weights_{CLEAN_TARGET_ARTIST_NAME}_strategy_{CURRENT_DROPOUT_STRATEGY}_best.pt\"\n",
    "model_save_filepath = os.path.join(MODEL_DIR_ARTIST, MODEL_SAVE_FILENAME)\n",
    "\n",
    "if not os.path.exists(model_save_filepath):\n",
    "    print(f\"Erro: Modelo treinado '{model_save_filepath}' para a estratégia '{CURRENT_DROPOUT_STRATEGY}' não encontrado.\")\n",
    "else:\n",
    "    model = CharLSTM(\n",
    "        vocab_size=total_chars,\n",
    "        embedding_dim=EMBEDDING_DIM,\n",
    "        hidden_dim=HIDDEN_DIM,\n",
    "        n_layers=N_LAYERS,\n",
    "        dropout_rate=DROPOUT_RATE,\n",
    "        dropout_strategy=CURRENT_DROPOUT_STRATEGY\n",
    "    ).to(device)\n",
    "\n",
    "    model.load_state_dict(torch.load(model_save_filepath, map_location=device))\n",
    "    print(f\"Modelo '{MODEL_SAVE_FILENAME}' carregado de: {model_save_filepath}\")\n",
    "\n",
    "    test_loss, test_accuracy = evaluate_model_loss_acc(model, test_loader, criterion, device)\n",
    "    perplexity = np.exp(test_loss) if not np.isnan(test_loss) else float('nan')\n",
    "    print(f\"\\nPerplexidade no conjunto de teste: {perplexity:.4f}\")\n",
    "\n",
    "    correct_pos_predictions = 0\n",
    "    correct_word_predictions = 0\n",
    "    total_predictions_attempted = 0\n",
    "    pos_confusion_matrix = {}\n",
    "    generated_words_list = []\n",
    "\n",
    "    if not prompts_for_eval or not true_next_words or not nlp:\n",
    "        print(\"\\nAviso: Dados insuficientes para a avaliação de nível de palavra. Pulando.\")\n",
    "    else:\n",
    "        print(f\"\\nIniciando avaliação de nível de palavra para {len(prompts_for_eval)} prompts...\")\n",
    "        for i in tqdm(range(len(prompts_for_eval)), desc=\"Avaliando Próxima Palavra & POS Tag\"):\n",
    "            prompt = prompts_for_eval[i]\n",
    "            true_word = true_next_words[i]\n",
    "            true_pos = true_next_pos_tags[i]\n",
    "\n",
    "            generated_word = generate_next_word_from_prompt_eval(model, tokenizer, prompt, SEQUENCE_LENGTH, device)\n",
    "            generated_words_list.append(generated_word)\n",
    "\n",
    "            generated_pos = \"NONE\"\n",
    "            if generated_word:\n",
    "                doc_generated = nlp(generated_word)\n",
    "                generated_pos = doc_generated[0].pos_ if doc_generated and doc_generated[0] else \"UNKNOWN\"\n",
    "            \n",
    "            pos_confusion_matrix.setdefault(true_pos, {})\n",
    "            pos_confusion_matrix[true_pos].setdefault(generated_pos, 0)\n",
    "            pos_confusion_matrix[true_pos][generated_pos] += 1\n",
    "\n",
    "            if generated_pos == true_pos:\n",
    "                correct_pos_predictions += 1\n",
    "            \n",
    "            cleaned_true_word = re.sub(r'[^a-z0-9]', '', true_word).lower()\n",
    "            cleaned_generated_word = re.sub(r'[^a-z0-9]', '', generated_word).lower()\n",
    "\n",
    "            if cleaned_generated_word == cleaned_true_word and cleaned_true_word != \"\":\n",
    "                correct_word_predictions += 1\n",
    "            total_predictions_attempted += 1\n",
    "\n",
    "        overall_pos_accuracy = (correct_pos_predictions / total_predictions_attempted) * 100 if total_predictions_attempted > 0 else 0.0\n",
    "        overall_word_accuracy = (correct_word_predictions / total_predictions_attempted) * 100 if total_predictions_attempted > 0 else 0.0\n",
    "\n",
    "        print(f\"\\nResultados de Coesão Gramatical e Predição da Próxima Palavra (Dropout: {CURRENT_DROPOUT_STRATEGY})\")\n",
    "        print(f\"Total de prompts avaliados: {total_predictions_attempted}\")\n",
    "        print(f\"Acurácia da Próxima Etiqueta POS: {overall_pos_accuracy:.2f}%\")\n",
    "        print(f\"Acurácia da Próxima Palavra: {overall_word_accuracy:.2f}%\")\n",
    "\n",
    "        print(\"\\nMétricas para o conjunto de PALAVRAS GERADAS (na tarefa de predição)\")\n",
    "        generated_word_metrics = calculate_text_quality_metrics(\" \".join(generated_words_list), existing_words_in_corpus)\n",
    "        for key, value in generated_word_metrics.items():\n",
    "            print(f\"{key.replace('_', ' ').title()}: {value:.4f}\")\n",
    "\n",
    "        print(\"\\nMétricas para o conjunto de PALAVRAS REAIS (do conjunto de teste)\")\n",
    "        actual_test_word_metrics = calculate_text_quality_metrics(\" \".join(true_next_words), existing_words_in_corpus)\n",
    "        for key, value in actual_test_word_metrics.items():\n",
    "            print(f\"{key.replace('_', ' ').title()}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d31ed7d",
   "metadata": {},
   "source": [
    "### before_fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337d9aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo 'model_weights_arianagrande_strategy_before_fc_best.pt' carregado de: models_by_artist_char_split\\arianagrande\\model_weights_arianagrande_strategy_before_fc_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avaliando: 100%|██████████| 332/332 [00:13<00:00, 24.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Resultados da Avaliação no Conjunto de TESTE para 'ArianaGrande' (Dropout: before_fc) ---\n",
      "Perda de Teste (Test Loss): 1.0780\n",
      "Acurácia de Teste (Test Accuracy): 0.6858\n",
      "-----------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "CURRENT_DROPOUT_STRATEGY = \"before_fc\" \n",
    "MODEL_SAVE_FILENAME = f\"model_weights_{CLEAN_TARGET_ARTIST_NAME}_strategy_{CURRENT_DROPOUT_STRATEGY}_best.pt\"\n",
    "model_save_filepath = os.path.join(MODEL_DIR_ARTIST, MODEL_SAVE_FILENAME)\n",
    "\n",
    "if not os.path.exists(model_save_filepath):\n",
    "    print(f\"Erro: Modelo treinado '{model_save_filepath}' para estratégia '{CURRENT_DROPOUT_STRATEGY}' não encontrado. Por favor, treine este modelo primeiro.\")\n",
    "    exit()\n",
    "\n",
    "model = CharLSTM(\n",
    "    vocab_size=total_chars,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    n_layers=N_LAYERS,\n",
    "    dropout_rate=DROPOUT_RATE,\n",
    "    dropout_strategy=CURRENT_DROPOUT_STRATEGY \n",
    ").to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(model_save_filepath, map_location=device))\n",
    "print(f\"Modelo '{MODEL_SAVE_FILENAME}' carregado de: {model_save_filepath}\")\n",
    "\n",
    "test_loss, test_accuracy = evaluate_model_loss_acc(model, test_loader, criterion, device)\n",
    "\n",
    "print(f\"\\n--- Resultados da Avaliação no Conjunto de TESTE para '{TARGET_ARTIST}' (Dropout: {CURRENT_DROPOUT_STRATEGY}) ---\")\n",
    "print(f\"Perda de Teste (Test Loss): {test_loss:.4f}\")\n",
    "print(f\"Acurácia de Teste (Test Accuracy): {test_accuracy:.4f}\")\n",
    "print(\"-----------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6406bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- AVALIAÇÃO: Modelo com Dropout 'none' ---\n",
      "Model 'model_weights_arianagrande_strategy_before_fc_best.pt' loaded from: models_by_artist_char_split\\arianagrande\\model_weights_arianagrande_strategy_before_fc_best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Loss/Acc: 100%|██████████| 352/352 [00:12<00:00, 28.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Resultados de Avaliação no Conjunto de TESTE (Caracter): 'ArianaGrande' (Dropout: before_fc) ---\n",
      "Perplexity: 2.3198\n",
      "-----------------------------------------------------\n",
      "\n",
      "Starting word-level evaluation for 9916 test prompts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating Next Word & POS Tag: 100%|██████████| 9916/9916 [09:25<00:00, 17.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Results: Grammatical Cohesion (POS) & Next Word Accuracy (Dropout: before_fc) ---\n",
      "Total prompts evaluated: 9916\n",
      "Correct POS Tag Predictions: 4852\n",
      "Overall Next POS Tag Accuracy: 48.93%\n",
      "Correct Next Word Predictions: 3056\n",
      "Overall Next Word Prediction Accuracy: 30.82%\n",
      "-----------------------------------------------------\n",
      "\n",
      "--- Metrics for GENERATED WORDS (from next-word prediction task) ---\n",
      "Total Generated Words: 10219\n",
      "Unique Generated Words: 357\n",
      "TTR (Generated Words): 0.0349\n",
      "Repetition Rate (Generated Words): 0.9651\n",
      "Generated Unique Words Existing in Corpus: 334\n",
      "Existence Rate (Generated Unique Words): 0.94%\n",
      "-----------------------------------------------------\n",
      "\n",
      "--- Metrics for ACTUAL TEST WORDS (from artist's test set) ---\n",
      "Total Actual Test Words: 9916\n",
      "Unique Actual Test Words: 998\n",
      "TTR (Actual Test Words): 0.1006\n",
      "Repetition Rate (Actual Test Words): 0.8994\n",
      "Actual Unique Words Existing in Corpus: 998\n",
      "Existence Rate (Actual Unique Words): 1.00%\n",
      "-----------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Executa uma avaliação focada na predição da próxima palavra para um modelo\n",
    "específico. Carrega os pesos do modelo, calcula a perplexidade no conjunto\n",
    "de teste e, em seguida, avalia a precisão da próxima palavra e da próxima\n",
    "etiqueta POS. Também analisa e compara as métricas de qualidade (TTR, taxa\n",
    "de repetição) do conjunto de palavras geradas versus o conjunto de palavras\n",
    "reais do teste.\n",
    "\"\"\"\n",
    "print(\"\\nAvaliação do Modelo com Dropout 'before_fc': Foco em Predição da Próxima Palavra\")\n",
    "CURRENT_DROPOUT_STRATEGY = \"before_fc\"\n",
    "MODEL_SAVE_FILENAME = f\"model_weights_{CLEAN_TARGET_ARTIST_NAME}_strategy_{CURRENT_DROPOUT_STRATEGY}_best.pt\"\n",
    "model_save_filepath = os.path.join(MODEL_DIR_ARTIST, MODEL_SAVE_FILENAME)\n",
    "\n",
    "if not os.path.exists(model_save_filepath):\n",
    "    print(f\"Erro: Modelo treinado '{model_save_filepath}' para a estratégia '{CURRENT_DROPOUT_STRATEGY}' não encontrado.\")\n",
    "else:\n",
    "    model = CharLSTM(\n",
    "        vocab_size=total_chars,\n",
    "        embedding_dim=EMBEDDING_DIM,\n",
    "        hidden_dim=HIDDEN_DIM,\n",
    "        n_layers=N_LAYERS,\n",
    "        dropout_rate=DROPOUT_RATE,\n",
    "        dropout_strategy=CURRENT_DROPOUT_STRATEGY\n",
    "    ).to(device)\n",
    "\n",
    "    model.load_state_dict(torch.load(model_save_filepath, map_location=device))\n",
    "    print(f\"Modelo '{MODEL_SAVE_FILENAME}' carregado de: {model_save_filepath}\")\n",
    "\n",
    "    test_loss, test_accuracy = evaluate_model_loss_acc(model, test_loader, criterion, device)\n",
    "    perplexity = np.exp(test_loss) if not np.isnan(test_loss) else float('nan')\n",
    "    print(f\"\\nPerplexidade no conjunto de teste: {perplexity:.4f}\")\n",
    "\n",
    "    correct_pos_predictions = 0\n",
    "    correct_word_predictions = 0\n",
    "    total_predictions_attempted = 0\n",
    "    pos_confusion_matrix = {}\n",
    "    generated_words_list = []\n",
    "\n",
    "    if not prompts_for_eval or not true_next_words or not nlp:\n",
    "        print(\"\\nAviso: Dados insuficientes para a avaliação de nível de palavra. Pulando.\")\n",
    "    else:\n",
    "        print(f\"\\nIniciando avaliação de nível de palavra para {len(prompts_for_eval)} prompts...\")\n",
    "        for i in tqdm(range(len(prompts_for_eval)), desc=\"Avaliando Próxima Palavra & POS Tag\"):\n",
    "            prompt = prompts_for_eval[i]\n",
    "            true_word = true_next_words[i]\n",
    "            true_pos = true_next_pos_tags[i]\n",
    "\n",
    "            generated_word = generate_next_word_from_prompt_eval(model, tokenizer, prompt, SEQUENCE_LENGTH, device)\n",
    "            generated_words_list.append(generated_word)\n",
    "\n",
    "            generated_pos = \"NONE\"\n",
    "            if generated_word:\n",
    "                doc_generated = nlp(generated_word)\n",
    "                generated_pos = doc_generated[0].pos_ if doc_generated and doc_generated[0] else \"UNKNOWN\"\n",
    "            \n",
    "            pos_confusion_matrix.setdefault(true_pos, {})\n",
    "            pos_confusion_matrix[true_pos].setdefault(generated_pos, 0)\n",
    "            pos_confusion_matrix[true_pos][generated_pos] += 1\n",
    "\n",
    "            if generated_pos == true_pos:\n",
    "                correct_pos_predictions += 1\n",
    "            \n",
    "            cleaned_true_word = re.sub(r'[^a-z0-9]', '', true_word).lower()\n",
    "            cleaned_generated_word = re.sub(r'[^a-z0-9]', '', generated_word).lower()\n",
    "\n",
    "            if cleaned_generated_word == cleaned_true_word and cleaned_true_word != \"\":\n",
    "                correct_word_predictions += 1\n",
    "            total_predictions_attempted += 1\n",
    "\n",
    "        overall_pos_accuracy = (correct_pos_predictions / total_predictions_attempted) * 100 if total_predictions_attempted > 0 else 0.0\n",
    "        overall_word_accuracy = (correct_word_predictions / total_predictions_attempted) * 100 if total_predictions_attempted > 0 else 0.0\n",
    "\n",
    "        print(f\"\\nResultados de Coesão Gramatical e Predição da Próxima Palavra (Dropout: {CURRENT_DROPOUT_STRATEGY})\")\n",
    "        print(f\"Total de prompts avaliados: {total_predictions_attempted}\")\n",
    "        print(f\"Acurácia da Próxima Etiqueta POS: {overall_pos_accuracy:.2f}%\")\n",
    "        print(f\"Acurácia da Próxima Palavra: {overall_word_accuracy:.2f}%\")\n",
    "\n",
    "        print(\"\\nMétricas para o conjunto de PALAVRAS GERADAS (na tarefa de predição)\")\n",
    "        generated_word_metrics = calculate_text_quality_metrics(\" \".join(generated_words_list), existing_words_in_corpus)\n",
    "        for key, value in generated_word_metrics.items():\n",
    "            print(f\"{key.replace('_', ' ').title()}: {value:.4f}\")\n",
    "\n",
    "        print(\"\\nMétricas para o conjunto de PALAVRAS REAIS (do conjunto de teste)\")\n",
    "        actual_test_word_metrics = calculate_text_quality_metrics(\" \".join(true_next_words), existing_words_in_corpus)\n",
    "        for key, value in actual_test_word_metrics.items():\n",
    "            print(f\"{key.replace('_', ' ').title()}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61527f79",
   "metadata": {},
   "source": [
    "## Geração do próximo caractere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4117003b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Gerando 10 exemplos aleatórios de predição do conjunto de TESTE ---\n",
      "\n",
      "Exemplo 1:\n",
      "  Input (sequence_length=100): 'in' 'bout you ooh oh yeah i'm just thinkin' 'bout you 'bout you 'bout you yeah i'm thinkin' 'bout yo'\n",
      "  Caracter Real Seguinte: 'u'\n",
      "  Caracter Previsto:      'u'\n",
      "  Acurado: Sim\n",
      "\n",
      "Exemplo 2:\n",
      "  Input (sequence_length=100): 'eart only girl in the world like i'm the only one that's in command cause i'm the only one who under'\n",
      "  Caracter Real Seguinte: 's'\n",
      "  Caracter Previsto:      'n'\n",
      "  Acurado: Não\n",
      "\n",
      "Exemplo 3:\n",
      "  Input (sequence_length=100): 'me with me we're on another mentality ain't got no tears left to cry to cry so i'm pickin' it up pic'\n",
      "  Caracter Real Seguinte: 'k'\n",
      "  Caracter Previsto:      'k'\n",
      "  Acurado: Sim\n",
      "\n",
      "Exemplo 4:\n",
      "  Input (sequence_length=100): 'ur love to me baby let me know are you wit it are you wit it are you wit it this christmas baby let '\n",
      "  Caracter Real Seguinte: 'm'\n",
      "  Caracter Previsto:      'm'\n",
      "  Acurado: Sim\n",
      "\n",
      "Exemplo 5:\n",
      "  Input (sequence_length=100): 'where and get you out of my hair i'm gonna have fun baby be so gone and when i get back you know you'\n",
      "  Caracter Real Seguinte: ' '\n",
      "  Caracter Previsto:      ' '\n",
      "  Acurado: Sim\n",
      "\n",
      "Exemplo 6:\n",
      "  Input (sequence_length=100): ' la la la not even sometimes la la la la la la la oh yeah la la la la la la la 'cause we're collecti'\n",
      "  Caracter Real Seguinte: 'n'\n",
      "  Caracter Previsto:      'o'\n",
      "  Acurado: Não\n",
      "\n",
      "Exemplo 7:\n",
      "  Input (sequence_length=100): 'n't you know all of them tears gon' come and go baby you just gotta make up your mind we decide it w'\n",
      "  Caracter Real Seguinte: 'e'\n",
      "  Caracter Previsto:      'e'\n",
      "  Acurado: Sim\n",
      "\n",
      "Exemplo 8:\n",
      "  Input (sequence_length=100): 'e me a day jamie bring back the lies hang them back on the wall maybe i'd see how you could be so ce'\n",
      "  Caracter Real Seguinte: 'r'\n",
      "  Caracter Previsto:      'n'\n",
      "  Acurado: Não\n",
      "\n",
      "Exemplo 9:\n",
      "  Input (sequence_length=100): 'and kiss me baby we don't need no mistletoe hmm we don't need no fireplace boy i'll keep you nice an'\n",
      "  Caracter Real Seguinte: 'd'\n",
      "  Caracter Previsto:      'd'\n",
      "  Acurado: Sim\n",
      "\n",
      "Exemplo 10:\n",
      "  Input (sequence_length=100): ' you away but i'm not ready so just get out of my face stop standing in my way i'm going out to say '\n",
      "  Caracter Real Seguinte: 'w'\n",
      "  Caracter Previsto:      'i'\n",
      "  Acurado: Não\n",
      "\n",
      "Geração de exemplos concluída.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Seleciona 10 exemplos aleatórios do conjunto de teste, utiliza o modelo\n",
    "carregado para prever o próximo caractere de cada sequência de entrada e\n",
    "exibe uma comparação lado a lado da sequência, do caractere real e do\n",
    "caractere previsto pelo modelo.\n",
    "\"\"\"\n",
    "print(\"\\nGerando 10 exemplos aleatórios de predição do conjunto de teste\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "num_examples_to_show = 10\n",
    "random_indices = random.sample(range(len(test_dataset)), min(num_examples_to_show, len(test_dataset)))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, idx in enumerate(random_indices):\n",
    "        input_sequence, actual_next_char_id = test_dataset[idx]\n",
    "        input_sequence_batch = input_sequence.unsqueeze(0).to(device)\n",
    "\n",
    "        output = model(input_sequence_batch)\n",
    "        _, predicted_next_char_id = torch.max(output, 1)\n",
    "\n",
    "        input_text = tokenizer.sequences_to_texts(input_sequence.tolist())\n",
    "        actual_char = tokenizer.sequences_to_texts([actual_next_char_id.item()])\n",
    "        predicted_char = tokenizer.sequences_to_texts([predicted_next_char_id.item()])\n",
    "\n",
    "        print(f\"\\nExemplo {i+1}:\")\n",
    "        print(f\"  Entrada (tamanho={SEQUENCE_LENGTH}): '{input_text}'\")\n",
    "        print(f\"  Caracter Real:                  '{actual_char}'\")\n",
    "        print(f\"  Caracter Previsto:              '{predicted_char}'\")\n",
    "        print(f\"  Correto:                        {'Sim' if actual_char == predicted_char else 'Não'}\")\n",
    "\n",
    "print(\"\\nGeração de exemplos concluída.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58258eb",
   "metadata": {},
   "source": [
    "## Geração de letras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8db516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cuda\n",
      "Objeto carregado de: processed_data_by_artist_char_split\\arianagrande\\tokenizers\\char_tokenizer_arianagrande.pkl\n",
      "Objeto carregado de: processed_data_by_artist_char_split\\arianagrande\\tokenizers\\vocab_size_arianagrande_char.pkl\n",
      "Vocabulário de caracteres carregado. Tamanho do vocabulário: 36\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Define uma função para geração de texto caractere a caractere, que utiliza\n",
    "uma 'seed' e um parâmetro de 'temperatura' para controlar a criatividade.\n",
    "Em seguida, carrega do disco o tokenizador e o tamanho do vocabulário\n",
    "necessários para a geração e para a instanciação do modelo.\n",
    "\"\"\"\n",
    "def generate_text(model, tokenizer, seed_text, num_generate=500, temperature=1.0, sequence_length=SEQUENCE_LENGTH, device=device):\n",
    "    \"\"\"Gera texto a partir de uma seed usando o modelo treinado.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    processed_seed_text = clean_text(seed_text) \n",
    "\n",
    "    if len(processed_seed_text) < sequence_length:\n",
    "        processed_seed_text = ' ' * (sequence_length - len(processed_seed_text)) + processed_seed_text\n",
    "    elif len(processed_seed_text) > sequence_length:\n",
    "        processed_seed_text = processed_seed_text[-sequence_length:]\n",
    "\n",
    "    generated_text = processed_seed_text\n",
    "\n",
    "    print(f\"Iniciando geração com a seed (ajustada para {sequence_length} caracteres): '{generated_text}'\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    for _ in tqdm(range(num_generate), desc=\"Gerando caracteres\"):\n",
    "        current_sequence_str = generated_text[-sequence_length:]\n",
    "        tokenized_input = tokenizer.texts_to_sequences(current_sequence_str)\n",
    "        \n",
    "        input_tensor = torch.tensor(tokenized_input, dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            predictions = model(input_tensor).squeeze(0)\n",
    "        \n",
    "        if temperature > 0:\n",
    "            predictions = predictions / temperature\n",
    "        \n",
    "        probabilities = torch.softmax(predictions, dim=-1)\n",
    "        next_char_id = torch.multinomial(probabilities, num_samples=1).item()\n",
    "        next_char = tokenizer.int_to_char.get(next_char_id, '')\n",
    "\n",
    "        generated_text += next_char\n",
    "\n",
    "    return generated_text\n",
    "\n",
    "try:\n",
    "    tokenizer = load_object(TOKENIZER_PATH)\n",
    "    total_chars = load_object(os.path.join(PROCESSED_DATA_DIR_ARTIST, TOKENIZER_SUBDIR, f'vocab_size_{CLEAN_TARGET_ARTIST_NAME}_char.pkl'))\n",
    "    print(f\"Vocabulário de caracteres carregado. Tamanho do vocabulário: {total_chars}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e496499a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed de exemplo para geração. \n",
    "seed_text = \"don't want nobody else around me just need you right here you're like the only thing that i see it's\"\n",
    "NUM_CHARS_TO_GENERATE = 120\n",
    "TEMPERATURE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16e2ebaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- GERAÇÃO: Modelo Sem Dropout (Estratégia 'none') ---\n",
      "Modelo 'model_weights_arianagrande_strategy_none_best.pt' carregado de: models_by_artist_char_split\\arianagrande\\model_weights_arianagrande_strategy_none_best.pt\n",
      "Iniciando geração com seed (ajustada para 100 caracteres): 'don't want nobody else around me just need you right here you're like the only thing that i see it's'\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gerando caracteres: 100%|██████████| 120/120 [00:02<00:00, 56.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Letra Gerada ---\n",
      "don't want nobody else around me just need you right here you're like the only thing that i see it's to you ou does it just like it when we were the one you to know that we got that's a liw can my soul is christmas is yo\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- GERAÇÃO: Modelo Sem Dropout (Estratégia 'none') ---\")\n",
    "\n",
    "CURRENT_DROPOUT_STRATEGY = \"none\" \n",
    "MODEL_SAVE_FILENAME = f\"model_weights_{CLEAN_TARGET_ARTIST_NAME}_strategy_{CURRENT_DROPOUT_STRATEGY}_best.pt\"\n",
    "model_save_filepath = os.path.join(MODEL_DIR_ARTIST, MODEL_SAVE_FILENAME)\n",
    "\n",
    "if not os.path.exists(model_save_filepath):\n",
    "    print(f\"Erro: Modelo treinado '{model_save_filepath}' para estratégia '{CURRENT_DROPOUT_STRATEGY}' não encontrado. Por favor, treine este modelo primeiro.\")\n",
    "else:\n",
    "    model = CharLSTM(\n",
    "        vocab_size=total_chars,\n",
    "        embedding_dim=EMBEDDING_DIM,\n",
    "        hidden_dim=HIDDEN_DIM,\n",
    "        n_layers=N_LAYERS,\n",
    "        dropout_rate=DROPOUT_RATE, \n",
    "        dropout_strategy=CURRENT_DROPOUT_STRATEGY \n",
    "    ).to(device)\n",
    "\n",
    "    model.load_state_dict(torch.load(model_save_filepath, map_location=device))\n",
    "    print(f\"Modelo '{MODEL_SAVE_FILENAME}' carregado de: {model_save_filepath}\")\n",
    "\n",
    "    generated_lyric = generate_text(model, tokenizer, seed_text, NUM_CHARS_TO_GENERATE, TEMPERATURE)\n",
    "\n",
    "    print(\"\\n--- Letra Gerada ---\")\n",
    "    print(generated_lyric)\n",
    "    print(\"--------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "64ce1813",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- GERAÇÃO: Modelo com Dropout 'between_lstm' ---\n",
      "Modelo 'model_weights_arianagrande_strategy_between_lstm_best.pt' carregado de: models_by_artist_char_split\\arianagrande\\model_weights_arianagrande_strategy_between_lstm_best.pt\n",
      "Iniciando geração com seed (ajustada para 100 caracteres): 'don't want nobody else around me just need you right here you're like the only thing that i see it's'\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gerando caracteres: 100%|██████████| 120/120 [00:01<00:00, 65.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Letra Gerada ---\n",
      "don't want nobody else around me just need you right here you're like the only thing that i see it's a leal is all for for people to love and i'm the hide you heard pre i'm but almost there grows you girls we can feel it\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- GERAÇÃO: Modelo com Dropout 'between_lstm' ---\")\n",
    "\n",
    "CURRENT_DROPOUT_STRATEGY = \"between_lstm\" \n",
    "MODEL_SAVE_FILENAME = f\"model_weights_{CLEAN_TARGET_ARTIST_NAME}_strategy_{CURRENT_DROPOUT_STRATEGY}_best.pt\"\n",
    "model_save_filepath = os.path.join(MODEL_DIR_ARTIST, MODEL_SAVE_FILENAME)\n",
    "\n",
    "if not os.path.exists(model_save_filepath):\n",
    "    print(f\"Erro: Modelo treinado '{model_save_filepath}' para estratégia '{CURRENT_DROPOUT_STRATEGY}' não encontrado. Por favor, treine este modelo primeiro.\")\n",
    "else:\n",
    "    model = CharLSTM(\n",
    "        vocab_size=total_chars,\n",
    "        embedding_dim=EMBEDDING_DIM,\n",
    "        hidden_dim=HIDDEN_DIM,\n",
    "        n_layers=N_LAYERS,\n",
    "        dropout_rate=DROPOUT_RATE, \n",
    "        dropout_strategy=CURRENT_DROPOUT_STRATEGY \n",
    "    ).to(device)\n",
    "\n",
    "    model.load_state_dict(torch.load(model_save_filepath, map_location=device))\n",
    "    print(f\"Modelo '{MODEL_SAVE_FILENAME}' carregado de: {model_save_filepath}\")\n",
    "\n",
    "    generated_lyric = generate_text(model, tokenizer, seed_text, NUM_CHARS_TO_GENERATE, TEMPERATURE)\n",
    "\n",
    "    print(\"\\n--- Letra Gerada ---\")\n",
    "    print(generated_lyric)\n",
    "    print(\"--------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b833480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- GERAÇÃO: Modelo com Dropout 'before_fc' ---\n",
      "Modelo 'model_weights_arianagrande_strategy_before_fc_best.pt' carregado de: models_by_artist_char_split\\arianagrande\\model_weights_arianagrande_strategy_before_fc_best.pt\n",
      "Iniciando geração com seed (ajustada para 100 caracteres): 'don't want nobody else around me just need you right here you're like the only thing that i see it's'\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gerando caracteres: 100%|██████████| 120/120 [00:01<00:00, 62.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Letra Gerada ---\n",
      "don't want nobody else around me just need you right here you're like the only thing that i see it's turnin' i ain't feelin' you but you shoulds know that you can have and for free mmmoons of cause you get it oh feel it \n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- GERAÇÃO: Modelo com Dropout 'before_fc' ---\")\n",
    "\n",
    "CURRENT_DROPOUT_STRATEGY = \"before_fc\" \n",
    "MODEL_SAVE_FILENAME = f\"model_weights_{CLEAN_TARGET_ARTIST_NAME}_strategy_{CURRENT_DROPOUT_STRATEGY}_best.pt\"\n",
    "model_save_filepath = os.path.join(MODEL_DIR_ARTIST, MODEL_SAVE_FILENAME)\n",
    "\n",
    "if not os.path.exists(model_save_filepath):\n",
    "    print(f\"Erro: Modelo treinado '{model_save_filepath}' para estratégia '{CURRENT_DROPOUT_STRATEGY}' não encontrado. Por favor, treine este modelo primeiro.\")\n",
    "else:\n",
    "    model = CharLSTM(\n",
    "        vocab_size=total_chars,\n",
    "        embedding_dim=EMBEDDING_DIM,\n",
    "        hidden_dim=HIDDEN_DIM,\n",
    "        n_layers=N_LAYERS,\n",
    "        dropout_rate=DROPOUT_RATE, \n",
    "        dropout_strategy=CURRENT_DROPOUT_STRATEGY \n",
    "    ).to(device)\n",
    "\n",
    "    model.load_state_dict(torch.load(model_save_filepath, map_location=device))\n",
    "    print(f\"Modelo '{MODEL_SAVE_FILENAME}' carregado de: {model_save_filepath}\")\n",
    "\n",
    "    generated_lyric = generate_text(model, tokenizer, seed_text, NUM_CHARS_TO_GENERATE, TEMPERATURE)\n",
    "\n",
    "    print(\"\\n--- Letra Gerada ---\")\n",
    "    print(generated_lyric)\n",
    "    print(\"--------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6986c39d",
   "metadata": {},
   "source": [
    "## Avaliação de acerto gramatical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d4adf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cuda\n",
      "Objeto carregado de: processed_data_by_artist_char_split\\arianagrande\\tokenizers\\char_tokenizer_arianagrande.pkl\n",
      "Objeto carregado de: processed_data_by_artist_char_split\\arianagrande\\tokenizers\\vocab_size_arianagrande_char.pkl\n",
      "Vocabulário de caracteres carregado. Tamanho do vocabulário: 36\n",
      "Modelo spaCy 'en_core_web_sm' carregado.\n",
      "Total de letras limpas de teste carregadas para avaliação: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gerando prompts e targets para avaliação: 100%|██████████| 32/32 [00:00<00:00, 4497.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de prompts e targets gerados para avaliação: 11279\n",
      "\n",
      "Fazendo POS Tagging das palavras verdadeiras...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "POS Tagging de palavras verdadeiras: 100%|██████████| 11279/11279 [00:43<00:00, 259.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- AVALIAÇÃO DE CLASSE GRAMATICAL: Modelo Caractere-a-Caractere com Dropout 'none' ---\n",
      "Modelo 'model_weights_arianagrande_strategy_none_best.pt' carregado.\n",
      "\n",
      "Iniciando avaliação de classe gramatical para 11279 prompts de teste...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avaliando POS Tag da próxima palavra: 100%|██████████| 11279/11279 [28:40<00:00,  6.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Resultados da Avaliação no Conjunto de TESTE (Dropout: none) ---\n",
      "Total de prompts avaliados: 11279\n",
      "Acertos de Classe Gramatical: 5883\n",
      "Precisão Geral da Classe Gramatical da Próxima Palavra: 52.16%\n",
      "\n",
      "--- Precisão por Classe Gramatical (quando deveria ser a classe X) ---\n",
      "  Quando deveria ser 'PRON': 76.01% (Acertos: 2376/3126)\n",
      "  Quando deveria ser 'SCONJ': 36.69% (Acertos: 102/278)\n",
      "  Quando deveria ser 'VERB': 45.84% (Acertos: 941/2053)\n",
      "  Quando deveria ser 'ADP': 47.22% (Acertos: 306/648)\n",
      "  Quando deveria ser 'NOUN': 47.20% (Acertos: 717/1519)\n",
      "  Quando deveria ser 'PART': 43.28% (Acertos: 87/201)\n",
      "  Quando deveria ser 'ADV': 36.73% (Acertos: 314/855)\n",
      "  Quando deveria ser 'PROPN': 28.24% (Acertos: 148/524)\n",
      "  Quando deveria ser 'AUX': 44.89% (Acertos: 211/470)\n",
      "  Quando deveria ser 'ADJ': 46.39% (Acertos: 289/623)\n",
      "  Quando deveria ser 'INTJ': 41.83% (Acertos: 215/514)\n",
      "  Quando deveria ser 'CCONJ': 36.63% (Acertos: 111/303)\n",
      "  Quando deveria ser 'X': 55.32% (Acertos: 26/47)\n",
      "  Quando deveria ser 'NUM': 35.45% (Acertos: 39/110)\n",
      "  Quando deveria ser 'PUNCT': 12.50% (Acertos: 1/8)\n",
      "\n",
      "--- Matriz de Confusão de Classes Gramatical (Simplificada) ---\n",
      "True \\ Pred    ADJ       ADP       ADV       AUX       CCONJ     DET       INTJ      NOUN      NUM       PART      PRON      PROPN     PUNCT     SCONJ     VERB      X         \n",
      "-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "ADJ            289       11        19        11        18        0         17        53        1         9         122       10        0         14        47        2         \n",
      "ADP            12        306       20        6         33        0         22        22        2         26        132       7         0         18        32        10        \n",
      "ADV            22        40        314       32        49        0         35        48        0         24        189       23        0         16        62        1         \n",
      "AUX            3         4         11        211       18        0         8         33        0         2         56        32        2         2         87        1         \n",
      "CCONJ          2         18        18        12        111       0         5         17        0         5         74        11        3         3         22        2         \n",
      "DET            0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         0         \n",
      "INTJ           14        26        15        5         15        0         215       14        1         6         150       13        0         11        28        1         \n",
      "NOUN           87        44        62        45        44        0         31        717       10        19        271       47        1         24        108       9         \n",
      "NUM            4         7         2         0         4         0         3         20        39        0         22        2         0         1         6         0         \n",
      "PART           1         7         10        1         9         0         2         13        0         87        55        4         0         6         6         0         \n",
      "PRON           25        67        104       29        88        2         69        113       5         48        2376      34        0         67        91        8         \n",
      "PROPN          16        14        26        12        45        0         22        70        1         2         106       148       0         5         53        4         \n",
      "PUNCT          0         1         0         0         0         0         0         0         0         0         3         1         1         2         0         0         \n",
      "SCONJ          2         12        7         4         9         0         7         13        1         8         98        3         0         102       12        0         \n",
      "VERB           43        55        75        208       93        0         53        130       2         28        318       79        2         17        941       9         \n",
      "X              1         0         3         2         1         0         2         0         0         0         6         1         0         0         5         26        \n",
      "-----------------------------------------------------\n",
      "\n",
      "--- AVALIAÇÃO DE CLASSE GRAMATICAL: Modelo Caractere-a-Caractere com Dropout 'between_lstm' ---\n",
      "Modelo 'model_weights_arianagrande_strategy_between_lstm_best.pt' carregado.\n",
      "\n",
      "Iniciando avaliação de classe gramatical para 11279 prompts de teste...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avaliando POS Tag da próxima palavra: 100%|██████████| 11279/11279 [19:36<00:00,  9.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Resultados da Avaliação no Conjunto de TESTE (Dropout: between_lstm) ---\n",
      "Total de prompts avaliados: 11279\n",
      "Acertos de Classe Gramatical: 6033\n",
      "Precisão Geral da Classe Gramatical da Próxima Palavra: 53.49%\n",
      "\n",
      "--- Precisão por Classe Gramatical (quando deveria ser a classe X) ---\n",
      "  Quando deveria ser 'PRON': 77.06% (Acertos: 2409/3126)\n",
      "  Quando deveria ser 'SCONJ': 25.54% (Acertos: 71/278)\n",
      "  Quando deveria ser 'VERB': 51.92% (Acertos: 1066/2053)\n",
      "  Quando deveria ser 'ADP': 44.29% (Acertos: 287/648)\n",
      "  Quando deveria ser 'NOUN': 47.73% (Acertos: 725/1519)\n",
      "  Quando deveria ser 'PART': 46.77% (Acertos: 94/201)\n",
      "  Quando deveria ser 'ADV': 33.45% (Acertos: 286/855)\n",
      "  Quando deveria ser 'PROPN': 38.74% (Acertos: 203/524)\n",
      "  Quando deveria ser 'AUX': 44.04% (Acertos: 207/470)\n",
      "  Quando deveria ser 'ADJ': 49.44% (Acertos: 308/623)\n",
      "  Quando deveria ser 'INTJ': 37.35% (Acertos: 192/514)\n",
      "  Quando deveria ser 'CCONJ': 38.28% (Acertos: 116/303)\n",
      "  Quando deveria ser 'X': 40.43% (Acertos: 19/47)\n",
      "  Quando deveria ser 'NUM': 44.55% (Acertos: 49/110)\n",
      "  Quando deveria ser 'PUNCT': 12.50% (Acertos: 1/8)\n",
      "\n",
      "--- Matriz de Confusão de Classes Gramatical (Simplificada) ---\n",
      "True \\ Pred    ADJ       ADP       ADV       AUX       CCONJ     INTJ      NOUN      NUM       PART      PRON      PROPN     PUNCT     SCONJ     VERB      X         \n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "ADJ            308       16        29        5         21        12        55        0         9         116       8         0         1         42        1         \n",
      "ADP            11        287       31        9         42        26        11        3         53        129       5         0         8         22        11        \n",
      "ADV            10        26        286       32        57        21        33        2         55        230       21        2         7         65        8         \n",
      "AUX            6         3         5         207       17        8         12        1         10        57        10        3         1         125       5         \n",
      "CCONJ          2         11        7         16        116       16        9         0         19        73        9         0         2         17        6         \n",
      "INTJ           6         17        14        7         24        192       28        1         24        142       14        2         10        30        3         \n",
      "NOUN           55        13        41        56        61        27        725       5         31        286       59        2         16        134       8         \n",
      "NUM            1         2         1         1         2         1         19        49        0         23        4         0         0         7         0         \n",
      "PART           0         21        6         0         13        3         1         0         94        53        3         0         2         3         2         \n",
      "PRON           19        55        61        22        96        47        58        10        123       2409      56        1         45        110       14        \n",
      "PROPN          12        4         11        18        38        22        52        8         7         91        203       0         9         43        6         \n",
      "PUNCT          1         1         0         0         3         0         0         0         1         1         0         1         0         0         0         \n",
      "SCONJ          1         12        8         9         6         13        6         0         15        124       8         0         71        5         0         \n",
      "VERB           29        25        53        161       66        45        127       3         49        332       61        4         13        1066      19        \n",
      "X              0         1         6         2         0         1         3         0         0         7         6         0         0         2         19        \n",
      "-----------------------------------------------------\n",
      "\n",
      "--- AVALIAÇÃO DE CLASSE GRAMATICAL: Modelo Caractere-a-Caractere com Dropout 'before_fc' ---\n",
      "Modelo 'model_weights_arianagrande_strategy_before_fc_best.pt' carregado.\n",
      "\n",
      "Iniciando avaliação de classe gramatical para 11279 prompts de teste...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avaliando POS Tag da próxima palavra: 100%|██████████| 11279/11279 [17:43<00:00, 10.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Resultados da Avaliação no Conjunto de TESTE (Dropout: before_fc) ---\n",
      "Total de prompts avaliados: 11279\n",
      "Acertos de Classe Gramatical: 5693\n",
      "Precisão Geral da Classe Gramatical da Próxima Palavra: 50.47%\n",
      "\n",
      "--- Precisão por Classe Gramatical (quando deveria ser a classe X) ---\n",
      "  Quando deveria ser 'PRON': 74.86% (Acertos: 2340/3126)\n",
      "  Quando deveria ser 'SCONJ': 35.25% (Acertos: 98/278)\n",
      "  Quando deveria ser 'VERB': 46.08% (Acertos: 946/2053)\n",
      "  Quando deveria ser 'ADP': 42.28% (Acertos: 274/648)\n",
      "  Quando deveria ser 'NOUN': 45.56% (Acertos: 692/1519)\n",
      "  Quando deveria ser 'PART': 47.76% (Acertos: 96/201)\n",
      "  Quando deveria ser 'ADV': 29.82% (Acertos: 255/855)\n",
      "  Quando deveria ser 'PROPN': 25.00% (Acertos: 131/524)\n",
      "  Quando deveria ser 'AUX': 45.53% (Acertos: 214/470)\n",
      "  Quando deveria ser 'ADJ': 44.94% (Acertos: 280/623)\n",
      "  Quando deveria ser 'INTJ': 33.46% (Acertos: 172/514)\n",
      "  Quando deveria ser 'CCONJ': 42.24% (Acertos: 128/303)\n",
      "  Quando deveria ser 'X': 51.06% (Acertos: 24/47)\n",
      "  Quando deveria ser 'NUM': 38.18% (Acertos: 42/110)\n",
      "  Quando deveria ser 'PUNCT': 12.50% (Acertos: 1/8)\n",
      "\n",
      "--- Matriz de Confusão de Classes Gramatical (Simplificada) ---\n",
      "True \\ Pred    ADJ       ADP       ADV       AUX       CCONJ     INTJ      NOUN      NUM       PART      PRON      PROPN     PUNCT     SCONJ     VERB      X         \n",
      "---------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "ADJ            280       27        28        3         19        5         56        0         6         128       12        1         7         47        4         \n",
      "ADP            1         274       47        9         70        19        17        3         19        132       6         0         17        29        5         \n",
      "ADV            16        37        255       44        55        14        65        4         33        226       28        0         13        60        5         \n",
      "AUX            4         5         11        214       23        4         28        0         5         48        11        2         0         114       1         \n",
      "CCONJ          1         10        8         8         128       9         24        0         11        60        8         0         7         22        7         \n",
      "INTJ           10        31        9         9         25        172       38        1         10        166       18        0         6         19        0         \n",
      "NOUN           52        42        58        26        93        23        692       19        31        241       50        0         11        175       6         \n",
      "NUM            1         4         2         3         2         3         16        42        4         18        2         0         0         10        3         \n",
      "PART           1         9         6         0         19        0         3         0         96        53        3         0         8         2         1         \n",
      "PRON           29        93        59        27        122       47        105       20        70        2340      42        0         89        74        9         \n",
      "PROPN          22        23        20        13        34        26        63        3         13        118       131       0         3         51        4         \n",
      "PUNCT          0         0         0         0         0         0         0         0         1         4         2         1         0         0         0         \n",
      "SCONJ          1         22        6         6         13        12        17        0         6         88        3         0         98        4         2         \n",
      "VERB           29        44        70        194       113       38        164       10        31        336       60        5         5         946       8         \n",
      "X              0         1         6         2         0         0         2         0         0         7         2         0         0         3         24        \n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Prepara um conjunto de dados detalhado para avaliação de previsão da próxima\n",
    "palavra, extraindo prompts e as classes gramaticais (POS tags) das\n",
    "palavras-alvo do conjunto de teste. Define e executa uma função de avaliação\n",
    "que carrega cada modelo pré-treinado (por estratégia de dropout), calcula a\n",
    "acurácia da previsão de POS tags e exibe os resultados, incluindo uma matriz\n",
    "de confusão.\n",
    "\"\"\"\n",
    "# --- Carregamento de Recursos ---\n",
    "try:\n",
    "    tokenizer = load_object(TOKENIZER_PATH)\n",
    "    total_chars = load_object(os.path.join(PROCESSED_DATA_DIR_ARTIST, TOKENIZER_SUBDIR, f'vocab_size_{CLEAN_TARGET_ARTIST_NAME}_char.pkl'))\n",
    "    print(f\"Vocabulário de caracteres carregado. Tamanho: {total_chars}\")\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    print(\"Modelo spaCy 'en_core_web_sm' carregado.\")\n",
    "except (FileNotFoundError, OSError) as e:\n",
    "    print(f\"Erro ao carregar recursos essenciais: {e}\")\n",
    "    print(\"Tentando baixar o modelo spaCy, se necessário...\")\n",
    "    try:\n",
    "        spacy.cli.download(\"en_core_web_sm\")\n",
    "        nlp = spacy.load(\"en_core_web_sm\")\n",
    "        print(\"Modelo spaCy baixado e carregado.\")\n",
    "    except Exception as download_e:\n",
    "        print(f\"Falha ao baixar e carregar o modelo spaCy: {download_e}\")\n",
    "        nlp = None\n",
    "\n",
    "# --- Preparação dos Dados de Avaliação ---\n",
    "prompts_for_eval = []\n",
    "true_next_words = []\n",
    "true_next_pos_tags = []\n",
    "try:\n",
    "    df_artist_full = pd.read_csv(CSV_FILE_PATH, usecols=['Lyric'])\n",
    "    all_lyrics_for_split = [clean_text(lyric) for lyric in df_artist_full['Lyric'] if clean_text(lyric)]\n",
    "    \n",
    "    random.seed(RANDOM_SEED)\n",
    "    random.shuffle(all_lyrics_for_split)\n",
    "    \n",
    "    num_train = int(len(all_lyrics_for_split) * TRAIN_SPLIT)\n",
    "    num_val = int(len(all_lyrics_for_split) * VAL_SPLIT)\n",
    "    test_lyrics_clean = all_lyrics_for_split[num_train + num_val:]\n",
    "\n",
    "    print(f\"Total de letras de teste para avaliação: {len(test_lyrics_clean)}\")\n",
    "    for lyric_text in tqdm(test_lyrics_clean, desc=\"Gerando prompts e alvos\"):\n",
    "        words_in_lyric = lyric_text.split()\n",
    "        for i in range(len(words_in_lyric) - 1):\n",
    "            context_string = \" \".join(words_in_lyric[:i+1])\n",
    "            target_word = words_in_lyric[i+1]\n",
    "            \n",
    "            prompt = (' ' * (SEQUENCE_LENGTH - len(context_string)) + context_string)[-SEQUENCE_LENGTH:]\n",
    "            \n",
    "            if target_word:\n",
    "                prompts_for_eval.append(prompt)\n",
    "                true_next_words.append(target_word)\n",
    "    \n",
    "    print(f\"Total de prompts e alvos gerados: {len(prompts_for_eval)}\")\n",
    "    if nlp and true_next_words:\n",
    "        docs = nlp.pipe(true_next_words, batch_size=500)\n",
    "        true_next_pos_tags = [doc[0].pos_ if doc and doc[0] else \"UNKNOWN\" for doc in tqdm(docs, total=len(true_next_words), desc=\"POS Tagging\")]\n",
    "except Exception as e:\n",
    "    print(f\"Erro ao preparar dados de teste: {e}\")\n",
    "\n",
    "# --- Função Principal de Avaliação ---\n",
    "def run_pos_evaluation_char_level(strategy, prompts, words, pos_tags, tokenizer_obj, device_obj, nlp_model):\n",
    "    print(f\"\\n--- AVALIAÇÃO DE CLASSE GRAMATICAL (Dropout: '{strategy}') ---\")\n",
    "    model_path = os.path.join(MODEL_DIR_ARTIST, f\"model_weights_{CLEAN_TARGET_ARTIST_NAME}_strategy_{strategy}_best.pt\")\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"Modelo para a estratégia '{strategy}' não encontrado em {model_path}. Pulando.\")\n",
    "        return\n",
    "\n",
    "    model = CharLSTM(total_chars, EMBEDDING_DIM, HIDDEN_DIM, N_LAYERS, DROPOUT_RATE, strategy).to(device_obj)\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device_obj))\n",
    "    model.eval()\n",
    "    print(f\"Modelo '{os.path.basename(model_path)}' carregado.\")\n",
    "\n",
    "    correct_pos = 0\n",
    "    confusion_matrix = {}\n",
    "    for i in tqdm(range(len(prompts)), desc=f\"Avaliando POS Tag (Dropout: {strategy})\"):\n",
    "        generated_word = generate_next_word_from_prompt_eval(model, tokenizer_obj, prompts[i], SEQUENCE_LENGTH, device_obj)\n",
    "        generated_pos = \"NONE\"\n",
    "        if generated_word:\n",
    "            doc = nlp_model(generated_word)\n",
    "            generated_pos = doc[0].pos_ if doc and doc[0] else \"UNKNOWN\"\n",
    "        \n",
    "        true_pos = pos_tags[i]\n",
    "        confusion_matrix.setdefault(true_pos, {})\n",
    "        confusion_matrix[true_pos].setdefault(generated_pos, 0)\n",
    "        confusion_matrix[true_pos][generated_pos] += 1\n",
    "        if generated_pos == true_pos:\n",
    "            correct_pos += 1\n",
    "            \n",
    "    accuracy = (correct_pos / len(prompts)) * 100 if prompts else 0\n",
    "    print(f\"Precisão Geral da Classe Gramatical da Próxima Palavra: {accuracy:.2f}%\")\n",
    "\n",
    "# --- Execução da Avaliação ---\n",
    "if prompts_for_eval:\n",
    "    run_pos_evaluation_char_level(\"none\", prompts_for_eval, true_next_words, true_next_pos_tags, tokenizer, device, nlp)\n",
    "    run_pos_evaluation_char_level(\"between_lstm\", prompts_for_eval, true_next_words, true_next_pos_tags, tokenizer, device, nlp)\n",
    "    run_pos_evaluation_char_level(\"before_fc\", prompts_for_eval, true_next_words, true_next_pos_tags, tokenizer, device, nlp)\n",
    "else:\n",
    "    print(\"Avaliação não executada devido à falta de prompts gerados.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_LyricGen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
